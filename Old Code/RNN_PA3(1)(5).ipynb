{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_PA3(1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "L9ixfY61Bege",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "imXc7RCu-at0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from collections import OrderedDict\n",
        "from itertools import chain\n",
        "import collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D3Uyb4HA-qKs",
        "colab_type": "code",
        "outputId": "4dbc9838-9162-491a-fcfe-3f2599a9842d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9qiGRxGP-r_R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('drive/My Drive/data_PA3/train.csv')\n",
        "valid= pd.read_csv('drive/My Drive/data_PA3/valid.csv')\n",
        "test = pd.read_csv('drive/My Drive/data_PA3/partial_test_400.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b_TD-gK-grSi",
        "colab_type": "code",
        "outputId": "3a0fc2d2-2846-4f26-96ae-905a7107d1f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "cell_type": "code",
      "source": [
        "#finding volcabulary size for English from the training data\n",
        "train_eng = train[\"ENG\"]\n",
        "train_eng = np.array(train_eng)\n",
        "print(train_eng.shape)\n",
        "\n",
        "p = list(OrderedDict.fromkeys(chain.from_iterable(train_eng)))\n",
        "input_vocab_size = len(p)+1\n",
        "print(input_vocab_size)\n",
        "print(p)\n",
        "\n",
        "valid_eng = valid[\"ENG\"]\n",
        "valid_eng = np.array(valid_eng)\n",
        "print(valid_eng.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13122,)\n",
            "45\n",
            "['R', ' ', 'A', 'S', 'V', 'I', 'H', 'E', 'D', 'O', 'G', 'N', '_', 'T', 'U', 'M', 'J', 'B', 'L', 'C', 'Y', 'K', 'Z', 'F', '-', 'W', 'P', 'Q', \"'\", 'X', '^', '/', '6', '(', ')', ',', 'É', '2', '.', '?', '4', 'Á', 'È', '1']\n",
            "(997,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UVyNT9Py55BD",
        "colab_type": "code",
        "outputId": "a72671c6-b0ba-4d5b-8aa5-9af4867d3d88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "#finding volcaublary size for Hindi from the training data\n",
        "train_hin = train[\"HIN\"]\n",
        "# print(train_temp)\n",
        "train_hin = np.array(train_hin)\n",
        "print(train_hin.shape)\n",
        "\n",
        "p = list(OrderedDict.fromkeys(chain.from_iterable(train_hin)))\n",
        "output_vocab_size = len(p)+1\n",
        "print(output_vocab_size)\n",
        "print(p)\n",
        "\n",
        "valid_hin = valid[\"HIN\"]\n",
        "valid_hin = np.array(valid_hin)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13122,)\n",
            "85\n",
            "['र', ' ', 'ा', 'स', 'व', 'ि', 'ह', 'ी', 'द', 'े', 'ग', 'न', '_', 'ो', 'ड', 'श', 'त', '्', 'ु', 'म', 'ज', 'ब', 'ै', 'ल', 'क', 'ॉ', '़', 'य', 'फ', 'ट', 'इ', 'ज़', 'ऑ', 'ं', 'थ', '-', 'ू', 'अ', 'ध', 'प', '\\u200d', 'छ', 'च', 'औ', 'ई', 'ॅ', 'आ', 'ख', 'ढ', 'ढ़', 'उ', 'झ', 'ँ', 'भ', 'ौ', 'ष', 'ण', 'घ', 'ठ', 'ए', 'ृ', 'क़', 'ऋ', 'ओ', 'ऐ', '/', 'ड़', '6', '(', ')', ',', 'ञ', \"'\", '2', '.', 'ऊ', '?', 'फ़', ':', '4', 'ख़', 'ग़', '1', '॥']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EPkld2qwnGP5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "building encoder\n"
      ]
    },
    {
      "metadata": {
        "id": "zAg2bE-P4dXH",
        "colab_type": "code",
        "outputId": "c4ec3194-7472-48f0-d6c1-c9206b74f29b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "inembsize = 256\n",
        "outembsize = 256\n",
        "batch_size = 20\n",
        "num_batches = len(train)//batch_size\n",
        "\n",
        "X_MAX_LENGTH = (max([len(train_eng[_]) for _ in range(len(train_eng))]))//2+1\n",
        "Y_MAX_LENGTH = (max([len(train_hin[_]) for _ in range(len(train_hin))]))//2+1\n",
        "\n",
        "num_epochs = 10\n",
        "state_size = 512  #64, 128, 256 was a good number for linux OS!\n",
        "encoder_layers = 1\n",
        "decoder_layers = 1\n",
        "learning_rate = 0.001\n",
        "learning_rate_decay = 0.1\n",
        "\n",
        "encoder_x = tf.placeholder(dtype=tf.int32, shape=[None, None]) #[batch_size, X_MAX_LENGTH]\n",
        "decoder_x = tf.placeholder(dtype=tf.int32, shape=[None, None]) #[batch_size, Y_MAX_LENGTH, Y_VOCAB_SIZE]\n",
        "y = tf.placeholder(dtype=tf.float32, shape=[None, None, None])#[batch_size, Y_MAX_LENGTH, Y_VOCAB_SIZE]\n",
        "#init_state = tf.placeholder(tf.float32, [encoder_layers, 2, batch_size, state_size])\n",
        "\n",
        "print(X_MAX_LENGTH)\n",
        "print(Y_MAX_LENGTH)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "61\n",
            "62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rtmkDkmzyWoT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def vectorize_data(batch_word, max_length, word_to_idx):\n",
        "    vec_word = np.zeros((len(batch_word), max_length, len(word_to_idx)), dtype=float)\n",
        "    for i, word in enumerate(batch_word):\n",
        "        for j, char in enumerate(word):\n",
        "            vec_word[i, j, char] = 1.\n",
        "    return vec_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SeZ4DeG9yaf8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_text(prediction, batch_size, length, vocab_size, idx_to_word):\n",
        "\n",
        "    batch_softmax = np.reshape(prediction, [batch_size, length, vocab_size])\n",
        "    batch_word = []\n",
        "\n",
        "    for word in batch_softmax:\n",
        "        new_word = ''\n",
        "        for char in word:\n",
        "            vector_position = np.argmax(char)\n",
        "            y_word = idx_to_word[vector_position]\n",
        "            if y_word != '#':\n",
        "                new_word = new_word + y_word + ' '\n",
        "            else:\n",
        "                new_word = new_word + ''\n",
        "        batch_word.append(new_word)\n",
        "\n",
        "    return batch_word\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HvqFl_c8Buw2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def variable_summaries(var):\n",
        "  \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
        "  with tf.name_scope('summaries'):\n",
        "    mean = tf.reduce_mean(var)\n",
        "    tf.summary.scalar('mean', mean)\n",
        "    with tf.name_scope('stddev'):\n",
        "      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
        "    tf.summary.scalar('stddev', stddev)\n",
        "    tf.summary.scalar('max', tf.reduce_max(var))\n",
        "    tf.summary.scalar('min', tf.reduce_min(var))\n",
        "    tf.summary.histogram('histogram', var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cs2vyRaZwed4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bn9keAIChKrv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(train_eng, train_hin, vocabulary_size = 100):\n",
        "    \n",
        "\n",
        "\n",
        "    # Feed input data in backwards for better translation performance.\n",
        "    x_data = [(tf.compat.as_str(train_eng[_]).lower().split(' ')) for _ in range(len(train_eng))]\n",
        "    x_data = [list(x_data[_]) for _ in range(len(x_data))]\n",
        "    X_DATA_SIZE = len(x_data)\n",
        "    print(x_data[0:2])\n",
        "\n",
        "    y_data = [(tf.compat.as_str(train_hin[_]).lower().split(' ')) for _ in range(len(train_hin))]\n",
        "    y_data = [list(y_data[_]) for _ in range(len(y_data))]\n",
        "    Y_DATA_SIZE = len(y_data)\n",
        "\n",
        "    print(y_data[0:2])\n",
        "\n",
        "    #Word Dictionary\n",
        "    x_word_list = []\n",
        "    y_word_list = []\n",
        "    [x_word_list.extend(x_data[_]) for _ in range(len(x_data))]\n",
        "    [y_word_list.extend(y_data[_]) for _ in range(len(y_data))]\n",
        "\n",
        "    x_word_dictionary = []\n",
        "    y_word_dictionary = []\n",
        "    x_word_dictionary.extend(collections.Counter(x_word_list).most_common(44))\n",
        "    y_word_dictionary.extend(collections.Counter(y_word_list).most_common(84))\n",
        "    \n",
        "    print(x_word_dictionary)\n",
        "\n",
        "    #word/idx mapping\n",
        "    x_idx_to_word = [word[0] for idx, word in enumerate(x_word_dictionary)]\n",
        "    x_idx_to_word.insert(0, '#')\n",
        "    x_idx_to_word.append('$')\n",
        "    print(x_idx_to_word[0:20])\n",
        "\n",
        "    y_idx_to_word = [word[0] for idx, word in enumerate(y_word_dictionary)]\n",
        "    y_idx_to_word.insert(0, '#') #at the first \n",
        "    y_idx_to_word.append('$') #at the last\n",
        "    print(y_idx_to_word[0:20])\n",
        "\n",
        "    x_word_to_idx = {word:ix for ix, word in enumerate(x_idx_to_word)}\n",
        "    y_word_to_idx = {word: ix for ix, word in enumerate(y_idx_to_word)}\n",
        "\n",
        "    X_VOCAB_SIZE = len(x_word_dictionary) + 2\n",
        "    Y_VOCAB_SIZE = len(y_word_dictionary) + 2\n",
        "\n",
        "    X_MAX_LENGTH = max([len(x_data[_]) for _ in range(len(x_data))])\n",
        "    Y_MAX_LENGTH = max([len(y_data[_]) for _ in range(len(y_data))])\n",
        "\n",
        "    return X_VOCAB_SIZE, Y_VOCAB_SIZE, x_idx_to_word, x_word_to_idx, y_idx_to_word, y_word_to_idx, X_MAX_LENGTH, Y_MAX_LENGTH, X_DATA_SIZE\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GOPM5vzBQtTF",
        "colab_type": "code",
        "outputId": "72d2a54b-106a-49d4-a3ce-ad374351bf69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "cell_type": "code",
      "source": [
        "X_VOCAB_SIZE, Y_VOCAB_SIZE, x_idx_to_word, x_word_to_idx, y_idx_to_word, y_word_to_idx, X_MAX_LENGTH, Y_MAX_LENGTH, X_DATA_SIZE = load_data(train_eng, train_hin\n",
        "                                                                                                                                            , 100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['r', 'a', 'a', 's', 'a', 'v', 'i', 'h', 'a', 'a', 'r', 'e', 'e'], ['d', 'e', 'o', 'g', 'a', 'n', '_', 'r', 'o', 'a', 'd']]\n",
            "[['र', 'ा', 'स', 'व', 'ि', 'ह', 'ा', 'र', 'ी'], ['द', 'े', 'व', 'ग', 'न', '_', 'र', 'ो', 'ड']]\n",
            "[('a', 22197), ('r', 9367), ('i', 8878), ('n', 8567), ('e', 8551), ('_', 6640), ('h', 6617), ('s', 5950), ('o', 5722), ('t', 5468), ('l', 5384), ('d', 4675), ('m', 4563), ('u', 4170), ('k', 3049), ('b', 2825), ('c', 2641), ('g', 2586), ('p', 2208), ('y', 2004), ('v', 1470), ('j', 1460), ('w', 1337), ('f', 1293), ('z', 545), ('q', 240), ('x', 136), ('-', 100), (\"'\", 58), (',', 32), ('.', 8), ('é', 7), ('^', 6), ('(', 6), (')', 6), ('/', 4), ('6', 2), ('2', 2), ('è', 2), ('?', 1), ('4', 1), ('á', 1), ('1', 1)]\n",
            "['#', 'a', 'r', 'i', 'n', 'e', '_', 'h', 's', 'o', 't', 'l', 'd', 'm', 'u', 'k', 'b', 'c', 'g', 'p']\n",
            "['#', 'ा', 'र', '्', '_', 'न', 'ि', 'ल', 'स', 'म', 'े', 'क', 'ी', 'व', 'ट', 'ो', 'ं', 'य', 'ब', 'द']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WpmDEaRYxFcZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_data(x_word_to_idx, y_word_to_idx, inputs = train_eng, labels = train_hin):\n",
        "\n",
        "\n",
        "    x_data = inputs\n",
        "    y_data = labels\n",
        "\n",
        "    #Feed input data in backwards for better translation performance.\n",
        "    x_data = [(tf.compat.as_str(x_data[_]).lower().split(' ')) for _ in range(len(x_data))]\n",
        "    x_data = [list(x_data[_]) for _ in range(len(x_data))]\n",
        "    #x_data = x_data[start_batch:end_batch]\n",
        "    \n",
        "    \n",
        "    y_data = [(tf.compat.as_str(y_data[_]).lower().split(' ')) for _ in range(len(y_data))]\n",
        "    y_data = [list(y_data[_]) for _ in range(len(y_data))]\n",
        "    #y_data = y_data[start_batch:end_batch]\n",
        "    \n",
        "    # Converting each character to its index value\n",
        "    for i, word in enumerate(x_data):\n",
        "        for j, charac in enumerate(word):\n",
        "            if charac in x_word_to_idx:\n",
        "                x_data[i][j] = x_word_to_idx[charac]\n",
        "            else:\n",
        "                x_data[i][j] = x_word_to_idx['$']\n",
        "\n",
        "    for i, word in enumerate(y_data):\n",
        "        for j, charac in enumerate(word):\n",
        "            if charac in y_word_to_idx:\n",
        "                y_data[i][j] = y_word_to_idx[charac]\n",
        "            else:\n",
        "                y_data[i][j] = y_word_to_idx['$']\n",
        "                \n",
        "    for _ in range(len(x_data)):\n",
        "      x_length = len(x_data[_])\n",
        "      y_length = len(y_data[_])\n",
        "\n",
        "      x_data[_].extend(np.zeros([X_MAX_LENGTH - x_length], dtype=int))\n",
        "      y_data[_].extend(np.zeros([Y_MAX_LENGTH - y_length], dtype=int))\n",
        "\n",
        "    return x_data, y_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NHB0cjBeCG_S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "restore = False\n",
        "ckpt_model_directory = 'drive/My Drive/data_files/training/saved_models'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aZFb7VoMHoI6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_data , y_data = get_data( x_word_to_idx, y_word_to_idx, inputs = train_eng, labels = train_hin)                                              "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HFNbGZXhgJ-J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_data_valid , y_data_valid = get_data(x_word_to_idx, y_word_to_idx, inputs = valid_eng, labels = valid_hin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "N8EeqiOjE2Rs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "outputId": "c3dbdb7b-b3b4-4ecd-c1b8-1252b08a4360"
      },
      "cell_type": "code",
      "source": [
        "with tf.variable_scope('encoder_word_embeddings'):\n",
        "\n",
        "    word_embeddings = tf.get_variable('encoder_word_embeddings', [X_VOCAB_SIZE, inembsize])\n",
        "    encoder_embedded_word_ids = tf.nn.embedding_lookup(word_embeddings, encoder_x)\n",
        "    encoder_embedded_word_ids = tf.reshape(encoder_embedded_word_ids, [-1, X_MAX_LENGTH, inembsize])\n",
        "\n",
        "with tf.variable_scope('encoder'):\n",
        "\n",
        "#             state_per_layer_list = tf.unstack(init_state, axis=0)\n",
        "#             rnn_tuple_state = tuple(\n",
        "#                 [tf.nn.rnn_cell.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])\n",
        "#                 for idx in range(encoder_layers)])\n",
        "\n",
        "#             encoder_stacked_cell = []\n",
        "\n",
        "#             for _ in range(encoder_layers):\n",
        "#                 encoder_single_cell = tf.nn.rnn_cell.LSTMCell(state_size, state_is_tuple=True)\n",
        "#                 if _ == 0:\n",
        "#                     with tf.name_scope('encoder_dropout') as scope:\n",
        "#                         encoder_single_cell = tf.nn.rnn_cell.DropoutWrapper(encoder_single_cell,\n",
        "#                                                         output_keep_prob=0.75)  # add dropout to first LSTM layer only.\n",
        "#                 encoder_stacked_cell.append(encoder_single_cell)\n",
        "\n",
        "#             encoder_cell = tf.nn.rnn_cell.MultiRNNCell(encoder_stacked_cell, state_is_tuple=True)\n",
        "\n",
        "#             encoder_outputs, encoder_state = tf.nn.dynamic_rnn(cell=encoder_cell,\n",
        "#                                                              inputs=encoder_embedded_word_ids,\n",
        "#                                                              dtype = tf.float32)\n",
        "\n",
        "            #del encoder_cell, state_per_layer_list, encoder_stacked_cell, rnn_tuple_state\n",
        "\n",
        "    for n in range(encoder_layers):\n",
        "          (out_fw, out_bw), (state_fw, state_bw) = tf.nn.bidirectional_dynamic_rnn(\n",
        "              cell_fw = tf.nn.rnn_cell.LSTMCell(state_size//2, state_is_tuple=True),  ## initializer, reuse to be set\n",
        "              cell_bw = tf.nn.rnn_cell.LSTMCell(state_size//2, state_is_tuple=True),  ## initializer, reuse to be set\n",
        "              inputs = encoder_embedded_word_ids,\n",
        "              \n",
        "              sequence_length =  [61]* batch_size,\n",
        "              dtype = tf.float32)\n",
        "\n",
        "          encoder_embedded_word_ids = tf.concat((out_fw, out_bw), 2)\n",
        "\n",
        "          bi_state_c = tf.concat((state_fw.c, state_bw.c), -1)\n",
        "          bi_state_h = tf.concat((state_fw.h, state_bw.h), -1)\n",
        "          bi_lstm_state = tf.nn.rnn_cell.LSTMStateTuple(c=bi_state_c, h=bi_state_h)\n",
        "          encoder_state = tuple([bi_lstm_state] * encoder_layers)\n",
        "\n",
        "          encoder_state = tuple(encoder_state[-1] for _ in range(encoder_layers))\n",
        "\n",
        "with tf.variable_scope('decoder_word_embeddings'):\n",
        "\n",
        "    word_embeddings = tf.get_variable('decoder_word_embeddings', [Y_VOCAB_SIZE, outembsize])\n",
        "    decoder_embedded_word_ids = tf.nn.embedding_lookup(word_embeddings, decoder_x)\n",
        "    #decoder_embedded_word_ids = tf.reshape(decoder_embedded_word_ids,\n",
        "                               #                 [-1, Y_MAX_LENGTH,  outembsize])\n",
        "\n",
        "\n",
        "with tf.variable_scope('decoder'):\n",
        "\n",
        "#             if decoder_layers != 0:\n",
        "#               null_state = np.zeros((decoder_layers-1, 2,  batch_size, state_size))\n",
        "#               null_state = tf.convert_to_tensor(null_state,dtype=tf.float32)\n",
        "#               encoder_final_state = tf.concat([encoder_final_state, null_state], 0)\n",
        "\n",
        "#               state_per_layer_list1 = tf.unstack(encoder_final_state, axis=0)\n",
        "#               encoder_final_state = tuple(\n",
        "#                 [tf.nn.rnn_cell.LSTMStateTuple(state_per_layer_list1[idx][0], state_per_layer_list1[idx][1])\n",
        "#                 for idx in range(decoder_layers)])  \n",
        "\n",
        "\n",
        "#             decoder_stacked_cell = []\n",
        "#             for _ in range(decoder_layers):\n",
        "#                 decoder_single_cell = tf.nn.rnn_cell.LSTMCell(state_size, state_is_tuple=True)  ## initializer, reuse to be set\n",
        "#                 if _ == 0:\n",
        "#                     with tf.name_scope('decoder_dropout') as scope:\n",
        "#                         decoder_single_cell = tf.nn.rnn_cell.DropoutWrapper(decoder_single_cell,\n",
        "#                                                     output_keep_prob=0.75)  \n",
        "#                 decoder_stacked_cell.append(decoder_single_cell)\n",
        "\n",
        "#             decoder_cell = tf.nn.rnn_cell.MultiRNNCell(decoder_stacked_cell, state_is_tuple=True)\n",
        "\n",
        "#             decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(cell= decoder_cell,\n",
        "#                                                              inputs=decoder_embedded_word_ids,\n",
        "#                                                            initial_state=encoder_final_state)\n",
        "\n",
        "    decoder_cell = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.LSTMCell(state_size) for _ in range(decoder_layers)])\n",
        "\n",
        "    dense_layer = tf.layers.Dense(Y_VOCAB_SIZE)\n",
        "\n",
        "    #decoder for training data\n",
        "    training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
        "            inputs = decoder_embedded_word_ids,\n",
        "            sequence_length = [62]* batch_size)\n",
        "\n",
        "    training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
        "            cell = decoder_cell,\n",
        "            helper = training_helper,\n",
        "            initial_state = encoder_state,\n",
        "            output_layer = dense_layer)\n",
        "\n",
        "    training_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
        "            decoder = training_decoder,\n",
        "            impute_finished = True,   ## impute finished make sure that weights causing correctly predicted words are not changed further\n",
        "            maximum_iterations = Y_MAX_LENGTH)   \n",
        "\n",
        "    #decoder for test data\n",
        "#             predicting_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
        "#                     embedding = decoder_embedded_word_ids,\n",
        "#                     start_tokens = tf.tile(tf.constant([GO], dtype=tf.int32), [batch_size]),\n",
        "#                     end_token = EOS)\n",
        "\n",
        "#             predicting_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
        "#                     cell = decoder_cell,\n",
        "#                     helper = predicting_helper,\n",
        "#                     initial_state = encoder_state,\n",
        "#                     output_layer = dense_layer)\n",
        "\n",
        "#             predicting_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
        "#                     decoder = predicting_decoder,\n",
        "#                     impute_finished = True,\n",
        "#                     maximum_iterations = 2 * (X_MAX_LENGTH))\n",
        "\n",
        "\n",
        "    training_logits = training_decoder_output.rnn_output\n",
        "    softmax_out = tf.nn.softmax(training_logits)\n",
        "\n",
        "    #predicting_ids = predicting_decoder_output.sample_id\n",
        "    #masks = tf.sequence_mask(tf.count_nonzero(decoder_x, 1, dtype=tf.int32), Y_MAX_LENGTH, dtype=tf.float32)  \n",
        "\n",
        "    #cost = tf.contrib.seq2seq.sequence_loss(logits = softmax_out,targets = decoder_x)\n",
        "                                                                                        \n",
        "    cost =  tf.nn.softmax_cross_entropy_with_logits(logits=training_logits, labels=y)\n",
        "    \n",
        "    total_cost = tf.reduce_mean(cost)\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(total_cost)\n",
        "\n",
        "    y_t = tf.argmax(softmax_out,axis=2)\n",
        "    y_t = tf.cast(y_t, tf.int32)\n",
        "\n",
        "    #prediction = tf.boolean_mask(y_t, masks)\n",
        "    prediction = y_t\n",
        "    #mask_label = tf.boolean_mask(decoder_x, masks)\n",
        "    mask_label = decoder_x\n",
        "    \n",
        "    correct_pred = tf.equal(prediction, mask_label)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "    saver = tf.train.Saver(max_to_keep=30)\n",
        "    #outputs = tf.reshape(decoder_outputs, [-1, state_size])\n",
        "\n",
        "#             with tf.name_scope('decoder_hidden_states') as scope:\n",
        "#                 W2 = tf.Variable(tf.random_normal([state_size, output_vocab_size]), dtype=tf.float32)\n",
        "#                 variable_summaries(W2)\n",
        "#                 b2 = tf.Variable(tf.zeros([1, output_vocab_size]), dtype=tf.float32)\n",
        "#                 variable_summaries(b2)\n",
        "\n",
        "#                 logits = tf.matmul(outputs, W2) + b2 # Broadcasted addition\n",
        "#                 tf.summary.histogram('pre_activations', logits)\n",
        "#                 prediction = tf.nn.softmax(logits)\n",
        "#                 tf.summary.histogram('activations', prediction)\n",
        "#             labels = y\n",
        "\n",
        "#         with tf.name_scope('cross_entropy') as scope:\n",
        "#             cost = tf.contrib.seq2seq.sequence_loss(logits = training_logits,\n",
        "#                                                      targets = y,\n",
        "#                                                      weights = masks)\n",
        "#             total_cost = tf.reduce_mean(cost)\n",
        "#             tf.summary.scalar('cross-entropy', total_cost)\n",
        "\n",
        "#         with tf.name_scope('optimizer') as scope:\n",
        "#             optimizer = tf.train.AdamOptimizer(learning_rate).minimize(total_cost)\n",
        "\n",
        "#         #Keep previous 30 model checkpoints..\n",
        "\n",
        "\n",
        "#return encoder_state, labels , training_logits, prediction\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-17-f9d3dea07218>:34: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-17-f9d3dea07218>:39: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From <ipython-input-17-f9d3dea07218>:86: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-17-f9d3dea07218>:132: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hKX06qd1BCNV",
        "colab_type": "code",
        "outputId": "03ab3830-fd41-4c3c-e839-dc89677d2bac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75473
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "\n",
        "    merged = tf.summary.merge_all()\n",
        "\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    epoch = 0\n",
        "\n",
        "#         if restore:\n",
        "#             print('Loading variables from {}'.format(ckpt_model_directory + nn_config.meta_file + nn_config.meta_num + nn_config.meta_ext))\n",
        "#             saver.restore(sess, nn_config.ckpt_model_directory + nn_config.meta_file + nn_config.meta_num)\n",
        "\n",
        "\n",
        "    #load data\n",
        "    while epoch<1: \n",
        "        epoch_loss = 0\n",
        "\n",
        "        for batch in range(num_batches):\n",
        "            start_batch = batch * batch_size\n",
        "            end_batch = start_batch + batch_size\n",
        "\n",
        "            batch_loss = 0\n",
        "\n",
        "            batch_x = x_data[start_batch:end_batch]\n",
        "            batch_y = y_data[start_batch:end_batch]\n",
        "\n",
        "\n",
        "            y_one_hot = vectorize_data(batch_y, Y_MAX_LENGTH, y_word_to_idx)\n",
        "            \n",
        "            opt = sess.run(optimizer, feed_dict={encoder_x: batch_x,decoder_x: batch_y,y: y_one_hot})\n",
        "            _total_cost, _accuracy, = sess.run([total_cost, accuracy], feed_dict={encoder_x: batch_x,decoder_x: batch_y,y: y_one_hot})     \n",
        "            logits, _prediction_series = sess.run([training_logits, softmax_out], feed_dict={encoder_x: batch_x,decoder_x: batch_y,y: y_one_hot})     \n",
        "            if batch % 1 == 0:\n",
        "\n",
        "                text = generate_text(_prediction_series, batch_size, Y_MAX_LENGTH, Y_VOCAB_SIZE, y_idx_to_word)\n",
        "\n",
        "                if epoch % 5 == 0:\n",
        "                    save_output_path = 'drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_{}_STATE-SIZE_{}_NUM-LAYERS_{}_LEARNING-RATE{}_EMBEDDING-SIZE_{}.txt'.format(epoch, state_size, decoder_layers, learning_rate, inembsize)\n",
        "\n",
        "                    with open(save_output_path,'w') as f:\n",
        "                       for item in text:\n",
        "                           f.write(\"%s\\n\" % item)\n",
        "                    print('[NOTIFICATION] Translation file saved to: {}'.format(save_output_path))\n",
        "\n",
        "                print('[INFO]: Batch {} optimized output for Epoch {}:'.format(batch, epoch))\n",
        "                for _ in range(batch_size):\n",
        "                    print(text[_])\n",
        "\n",
        "            batch_loss += _total_cost\n",
        "            epoch_loss += _total_cost\n",
        "\n",
        "            print('\\n[STATUS] Batch {}/{} complete! Batch Loss: {}'.format(batch, num_batches, batch_loss))\n",
        "            print(_accuracy)\n",
        "            print(batch)\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "\n",
        "            save_model_path = \"drive/My Drive/data_PA3/\"\n",
        "            if epoch == 0:\n",
        "                save_path = saver.save(sess, save_model_path, epoch)\n",
        "            else:\n",
        "                save_path = saver.save(sess, save_model_path, epoch, write_meta_graph=False)\n",
        "\n",
        "            print(\"[STATUS] Model ckpt saved in file: %s\" % save_path)\n",
        "\n",
        "        print('[STATUS] Epoch {} complete! Epoch Loss: {}'.format(epoch, epoch_loss))\n",
        "\n",
        "        saver.save(sess, save_model_path + '/model.ckpt', epoch)\n",
        "        epoch+=1\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 0 optimized output for Epoch 0:\n",
            "् \n",
            "ा ा \n",
            "् \n",
            "् \n",
            "ा \n",
            "\n",
            "् \n",
            "् \n",
            "् ् \n",
            "् \n",
            "् ् \n",
            "् \n",
            "् ् \n",
            "् \n",
            "ा ा \n",
            "् \n",
            "ा \n",
            "ा \n",
            "् \n",
            "् ् \n",
            "\n",
            "[STATUS] Batch 0/656 complete! Batch Loss: 3.681623697280884\n",
            "0.8516129\n",
            "0\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 1 optimized output for Epoch 0:\n",
            "\n",
            "\n",
            "\n",
            "ा \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ा \n",
            "\n",
            "\n",
            "ा \n",
            "ा \n",
            "ा \n",
            "\n",
            "ा \n",
            "\n",
            "ा \n",
            "\n",
            "\n",
            "[STATUS] Batch 1/656 complete! Batch Loss: 1.965707540512085\n",
            "0.8475807\n",
            "1\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 2 optimized output for Epoch 0:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[STATUS] Batch 2/656 complete! Batch Loss: 0.8378551602363586\n",
            "0.841129\n",
            "2\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 3 optimized output for Epoch 0:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[STATUS] Batch 3/656 complete! Batch Loss: 1.1745795011520386\n",
            "0.8201613\n",
            "3\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 4 optimized output for Epoch 0:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[STATUS] Batch 4/656 complete! Batch Loss: 1.0973405838012695\n",
            "0.8346774\n",
            "4\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 5 optimized output for Epoch 0:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ा \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ा \n",
            "\n",
            "\n",
            "[STATUS] Batch 5/656 complete! Batch Loss: 1.0177346467971802\n",
            "0.8266129\n",
            "5\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 6 optimized output for Epoch 0:\n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "\n",
            "[STATUS] Batch 6/656 complete! Batch Loss: 0.6561498641967773\n",
            "0.86451614\n",
            "6\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 7 optimized output for Epoch 0:\n",
            "ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा ा \n",
            "\n",
            "[STATUS] Batch 7/656 complete! Batch Loss: 0.6282393932342529\n",
            "0.86451614\n",
            "7\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 8 optimized output for Epoch 0:\n",
            "ा ा ा ा ा ा ा \n",
            "ा ा ा ा ा ा \n",
            "ा ा ा ा ा ा ा ा \n",
            "ा ा ा ा ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा ा ा ा ा ा ा ा - - ' 6 1 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 / \n",
            "ा ा ा ा ा ा \n",
            "ा ा ा ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा ा ा ा ा \n",
            "ा ा ा ा ा \n",
            "ा ा ा ा ा ा \n",
            "ा ा ा ा ा \n",
            "ा ा \n",
            "ा ा ा ा ा \n",
            "ा ा ा ा ा ा ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा ा ा ा ा ा \n",
            "ा ा ा ा ा ा ा ा ा \n",
            "\n",
            "[STATUS] Batch 8/656 complete! Batch Loss: 0.7370149493217468\n",
            "0.8637097\n",
            "8\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 9 optimized output for Epoch 0:\n",
            "ा ा ा ा ा \n",
            "ा ा ा ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा ा ा \n",
            "ा ा ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा ा ा \n",
            "ा ा ा ा ा ा \n",
            "ा ा ा ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा ा ा ा ा \n",
            "ा ा ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा ा ा ा ा \n",
            "ा ा ा ा ा ा \n",
            "\n",
            "[STATUS] Batch 9/656 complete! Batch Loss: 0.549562931060791\n",
            "0.8927419\n",
            "9\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 10 optimized output for Epoch 0:\n",
            "ा ा ा \n",
            "ा ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा \n",
            "ा ा \n",
            "ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा ा \n",
            "ा ा ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा \n",
            "ा ा ा ा \n",
            "ा ा \n",
            "\n",
            "[STATUS] Batch 10/656 complete! Batch Loss: 0.7387068867683411\n",
            "0.8467742\n",
            "10\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 11 optimized output for Epoch 0:\n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा ा \n",
            "\n",
            "[STATUS] Batch 11/656 complete! Batch Loss: 0.8739994168281555\n",
            "0.83064514\n",
            "11\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 12 optimized output for Epoch 0:\n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "\n",
            "[STATUS] Batch 12/656 complete! Batch Loss: 0.6247805953025818\n",
            "0.86612904\n",
            "12\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 13 optimized output for Epoch 0:\n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "\n",
            "[STATUS] Batch 13/656 complete! Batch Loss: 0.7983846664428711\n",
            "0.8379032\n",
            "13\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 14 optimized output for Epoch 0:\n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "\n",
            "[STATUS] Batch 14/656 complete! Batch Loss: 0.9047727584838867\n",
            "0.8129032\n",
            "14\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 15 optimized output for Epoch 0:\n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "\n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "\n",
            "ा \n",
            "ा \n",
            "\n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "\n",
            "[STATUS] Batch 15/656 complete! Batch Loss: 0.5784804821014404\n",
            "0.8830645\n",
            "15\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 16 optimized output for Epoch 0:\n",
            "\n",
            "\n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "\n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "\n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "\n",
            "[STATUS] Batch 16/656 complete! Batch Loss: 0.5980929732322693\n",
            "0.8717742\n",
            "16\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 17 optimized output for Epoch 0:\n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "\n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "\n",
            "[STATUS] Batch 17/656 complete! Batch Loss: 0.691770076751709\n",
            "0.8451613\n",
            "17\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 18 optimized output for Epoch 0:\n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "\n",
            "[STATUS] Batch 18/656 complete! Batch Loss: 0.7115901112556458\n",
            "0.83870965\n",
            "18\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 19 optimized output for Epoch 0:\n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "\n",
            "[STATUS] Batch 19/656 complete! Batch Loss: 0.6648896336555481\n",
            "0.8467742\n",
            "19\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 20 optimized output for Epoch 0:\n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "\n",
            "[STATUS] Batch 20/656 complete! Batch Loss: 0.5692607164382935\n",
            "0.8620968\n",
            "20\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 21 optimized output for Epoch 0:\n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "\n",
            "[STATUS] Batch 21/656 complete! Batch Loss: 0.467786580324173\n",
            "0.8862903\n",
            "21\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 22 optimized output for Epoch 0:\n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा \n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा \n",
            "ा ा \n",
            "\n",
            "[STATUS] Batch 22/656 complete! Batch Loss: 0.5374231934547424\n",
            "0.8669355\n",
            "22\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 23 optimized output for Epoch 0:\n",
            "ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा र \n",
            "ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा र \n",
            "ा ा \n",
            "ा ा ा \n",
            "ा ा \n",
            "ा ा र \n",
            "\n",
            "[STATUS] Batch 23/656 complete! Batch Loss: 0.5255416035652161\n",
            "0.8766129\n",
            "23\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 24 optimized output for Epoch 0:\n",
            "ा ा \n",
            "ा ा ा \n",
            "ा ा र \n",
            "ा ा ा ा र \n",
            "ा ा ा \n",
            "ा ा ा र \n",
            "ा ा ा र र \n",
            "ा ा \n",
            "ा ा र र \n",
            "ा ा ा \n",
            "ा ा ा ा र \n",
            "ा ा ा \n",
            "ा ा \n",
            "ा ा \n",
            "ा ा ा \n",
            "ा ा र \n",
            "ा ा ा \n",
            "ा ा ा \n",
            "ा ा र र र \n",
            "ा र ा \n",
            "\n",
            "[STATUS] Batch 24/656 complete! Batch Loss: 0.5662660598754883\n",
            "0.85967743\n",
            "24\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 25 optimized output for Epoch 0:\n",
            "ा ा ा र र \n",
            "ा ा ा र र र \n",
            "ा ा ा ा \n",
            "ा ा ा र र र \n",
            "ा ा र र र र र र \n",
            "ा ा ा ा र र र र \n",
            "ा ा ा र र र र \n",
            "ा \n",
            "ा ा ा र र \n",
            "ा ा र र र र \n",
            "ा ा र र \n",
            "ा ा ा ा र \n",
            "ा ा र र \n",
            "ा ा ा र र \n",
            "ा ा ा र र \n",
            "ा ा ा र \n",
            "ा ा ा र \n",
            "ा र र र र \n",
            "ा र र र र र \n",
            "ा ा ा ा र \n",
            "\n",
            "[STATUS] Batch 25/656 complete! Batch Loss: 0.5772140026092529\n",
            "0.8653226\n",
            "25\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 26 optimized output for Epoch 0:\n",
            "ा ा र र र र \n",
            "ा ा ा र र र \n",
            "ा ा र \n",
            "ा ा ा र र र र र \n",
            "ा ा ा र \n",
            "र ा ा र र र \n",
            "ा ् र र \n",
            "ा ा र ा र \n",
            "ा ा ा ा र र र र र \n",
            "ा ा र र र र \n",
            "ा ा र र र \n",
            "ा ा ा र र \n",
            "ा ा र र र \n",
            "ा ा ा र र र र र \n",
            "ा ा र र \n",
            "र ा \n",
            "र ा र ा र र \n",
            "ा ा \n",
            "ा ा ा र र र र र र \n",
            "ा ा र र र र \n",
            "\n",
            "[STATUS] Batch 26/656 complete! Batch Loss: 0.5050556659698486\n",
            "0.8862903\n",
            "26\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 27 optimized output for Epoch 0:\n",
            "ा ा \n",
            "ा ा र र र \n",
            "ा ा ा र र र र \n",
            "ा ा र र र \n",
            "ा ा र र र \n",
            "ा ा ा ा र र र र र \n",
            "ा ा र र र र र \n",
            "ा ा ा \n",
            "ा ा र \n",
            "ा ा ा र र र \n",
            "ा ा ा ा र र र र \n",
            "ा ा ा र र र र र र \n",
            "र ा र र र र \n",
            "ा ा र र र र र र \n",
            "ा ा ा र र र र र र र \n",
            "ा ा ा र र र \n",
            "ा ा ा र र र र र र \n",
            "ा ा ा र र \n",
            "ा ा र र र र र र \n",
            "ा ा ा र र र र \n",
            "\n",
            "[STATUS] Batch 27/656 complete! Batch Loss: 0.557798445224762\n",
            "0.86612904\n",
            "27\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 28 optimized output for Epoch 0:\n",
            "ा \n",
            "ा ा ा र र \n",
            "ा ा र र \n",
            "ा ा ा र र \n",
            "ा ा ा र र र \n",
            "ा ा र ा \n",
            "ा ा ा र र ा र \n",
            "ा ा र \n",
            "ा ा ा र र \n",
            "ा ा ा र \n",
            "ा ा र \n",
            "ा ा ा र \n",
            "ा ा र र र \n",
            "ा ा ा र ा र \n",
            "र ा र \n",
            "ा ा र \n",
            "ा ा ा ा र र र \n",
            "ा ा र \n",
            "ा ा र र \n",
            "ा ा र र \n",
            "\n",
            "[STATUS] Batch 28/656 complete! Batch Loss: 0.42674490809440613\n",
            "0.8967742\n",
            "28\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 29 optimized output for Epoch 0:\n",
            "ा ा \n",
            "ा ा ा र र \n",
            "् \n",
            "ा \n",
            "ा ा ा र र र \n",
            "ा ा ा ा र र र \n",
            "ा ा ा ा ा र \n",
            "ा ा ा ा र \n",
            "ा ा र र र \n",
            "ा ा \n",
            "् ा \n",
            "् र \n",
            "ा ा ा र \n",
            "ा ा ा \n",
            "ा र र र \n",
            "ा ा ा र र र र \n",
            "ा ा ा ा \n",
            "ा ा ा र \n",
            "् \n",
            "ा ा ा र र \n",
            "\n",
            "[STATUS] Batch 29/656 complete! Batch Loss: 0.6201029419898987\n",
            "0.84354836\n",
            "29\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 30 optimized output for Epoch 0:\n",
            "\n",
            "् \n",
            "् ् र \n",
            "् \n",
            "\n",
            "ा ा ा ा र र \n",
            "् \n",
            "् \n",
            "् ा ा \n",
            "ा ा ा \n",
            "ा ा र \n",
            "ा ा ा \n",
            "ा ा ा \n",
            "ा ा र र \n",
            "् ् र \n",
            "ा ा \n",
            "\n",
            "् ा ा र \n",
            "ा ा र \n",
            "ा र र ा र र \n",
            "\n",
            "[STATUS] Batch 30/656 complete! Batch Loss: 0.5336275696754456\n",
            "0.8669355\n",
            "30\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 31 optimized output for Epoch 0:\n",
            "ा ा र र र ा ा \n",
            "् \n",
            "ा ा ा ा ा ा ा ा र ा ा ा ा ा \n",
            "ा ा ा ा ा ा ा ा ा ा ा \n",
            "् \n",
            "\n",
            "\n",
            "\n",
            "् \n",
            "् \n",
            "\n",
            "् \n",
            "ा ा ा ा ा ा ा \n",
            "ा ा ा ा \n",
            "ा ा र र र र र \n",
            "् \n",
            "ा ् र र ा ा र र र \n",
            "् ् \n",
            "\n",
            "् ा ा ा र र \n",
            "\n",
            "[STATUS] Batch 31/656 complete! Batch Loss: 0.6298394799232483\n",
            "0.8427419\n",
            "31\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 32 optimized output for Epoch 0:\n",
            "\n",
            "् \n",
            "\n",
            "ा ा ा ा ा र र ा ा ा ा ा ा ा ा ा ा ा ा ा ा ा \n",
            "\n",
            "् ा र र ा र ा र ा \n",
            "् ् र र र र र र ा ा ा ा ा \n",
            "\n",
            "् र र र र \n",
            "ा ा र र र र र ा ा र ा ा र \n",
            "\n",
            "् \n",
            "र र र र र र र र ा ा ा र \n",
            "् \n",
            "् \n",
            "् \n",
            "् \n",
            "ा ा ा ा ा र र ा ा ा ा ा ा ा ा ा ा ा ा ा ा ा \n",
            "् \n",
            "् र \n",
            "\n",
            "[STATUS] Batch 32/656 complete! Batch Loss: 0.550491988658905\n",
            "0.8717742\n",
            "32\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 33 optimized output for Epoch 0:\n",
            "् \n",
            "\n",
            "\n",
            "् ा ा ा ा ा \n",
            "् ा र ् ा ा ा ा ा ा ा ा ा \n",
            "\n",
            "् ् ा ा ा ा र ा ा ा ा \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "् ा र ा ा ा ा ा \n",
            "् ा र ा ा ा ा र ा ा \n",
            "\n",
            "\n",
            "् ा ा ा र \n",
            "् ् \n",
            "् ा ा र ा \n",
            "\n",
            "\n",
            "[STATUS] Batch 33/656 complete! Batch Loss: 0.5289600491523743\n",
            "0.8733871\n",
            "33\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 34 optimized output for Epoch 0:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "् ा र ा ा ा \n",
            "् _ ा ा \n",
            "\n",
            "\n",
            "् ् ा _ ा ा ा _ ा ा ा ा ा ा ा ा ा ा ा \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[STATUS] Batch 34/656 complete! Batch Loss: 0.5187764763832092\n",
            "0.8637097\n",
            "34\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 35 optimized output for Epoch 0:\n",
            "\n",
            "\n",
            "\n",
            "_ _ ा ा ा \n",
            "\n",
            "\n",
            "् ् ा _ _ ा ा ा ा ा ा \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "् \n",
            "\n",
            "\n",
            "\n",
            "[STATUS] Batch 35/656 complete! Batch Loss: 0.5352161526679993\n",
            "0.858871\n",
            "35\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 36 optimized output for Epoch 0:\n",
            "\n",
            "\n",
            "् ् र र _ _ \n",
            "् \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "् ा र ा ा \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[STATUS] Batch 36/656 complete! Batch Loss: 0.49176025390625\n",
            "0.86935484\n",
            "36\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 37 optimized output for Epoch 0:\n",
            "\n",
            "् \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "् \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "् \n",
            "\n",
            "ा ा र ा ा ा _ \n",
            "् \n",
            "् \n",
            "\n",
            "\n",
            "[STATUS] Batch 37/656 complete! Batch Loss: 0.5031167268753052\n",
            "0.86290324\n",
            "37\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 38 optimized output for Epoch 0:\n",
            "\n",
            "\n",
            "् \n",
            "् \n",
            "् \n",
            "् र र \n",
            "ा ा ा ा ा _ _ र _ _ _ _ _ \n",
            "् ् ् \n",
            "् र र \n",
            "\n",
            "\n",
            "् ा \n",
            "् \n",
            "् ् \n",
            "् ा र ् \n",
            "ा ् ा ा ा ा _ \n",
            "् \n",
            "् \n",
            "् ् \n",
            "\n",
            "\n",
            "[STATUS] Batch 38/656 complete! Batch Loss: 0.5621533393859863\n",
            "0.8532258\n",
            "38\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 39 optimized output for Epoch 0:\n",
            "र र ् र ा _ \n",
            "् \n",
            "् ा ा \n",
            "् ा र _ ा \n",
            "ा ा ा ा ा ा _ _ _ _ _ _ _ _ \n",
            "् \n",
            "् र \n",
            "ा ा ा ा ् _ \n",
            "ा ा ा ा \n",
            "् ् \n",
            "् ् \n",
            "् ् \n",
            "् ् \n",
            "् ा ा \n",
            "् \n",
            "ा ा ा ा र ा _ _ _ _ _ \n",
            "् ् \n",
            "र ा ा ् र _ \n",
            "् ् र \n",
            "् \n",
            "\n",
            "[STATUS] Batch 39/656 complete! Batch Loss: 0.5560504794120789\n",
            "0.8604839\n",
            "39\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 40 optimized output for Epoch 0:\n",
            "ा ा ा ा ा र ् _ _ _ _ _ _ _ _ \n",
            "् ा र र \n",
            "ा ा र ् र _ _ \n",
            "् र र र \n",
            "र ा र र \n",
            "र र र \n",
            "ा ा र र _ _ _ _ _ \n",
            "् ् ् \n",
            "र र र ा ा \n",
            "र र ा ा ा ा _ _ ा \n",
            "ा ् र र र _ _ _ _ _ _ _ \n",
            "ा ा ा ा ा र ् _ _ _ _ _ _ _ _ _ _ \n",
            "् र ् \n",
            "ा ा ा ा ा _ \n",
            "र र \n",
            "र र ् ा ा ा _ र \n",
            "र ् र र ा ा _ र _ \n",
            "् ् \n",
            "् ् र \n",
            "ा ा ा ् ा ा _ _ र ा _ _ _ _ _ \n",
            "\n",
            "[STATUS] Batch 40/656 complete! Batch Loss: 0.5965479016304016\n",
            "0.86290324\n",
            "40\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 41 optimized output for Epoch 0:\n",
            "ा ा ा ा ा ा _ \n",
            "र ा र ् \n",
            "र ् ् ा र \n",
            "ा ा ा ा ा _ _ _ \n",
            "र र ा ा ा ा _ _ _ _ \n",
            "ा र र र र ा \n",
            "् र र ् \n",
            "् र र र \n",
            "ा ा र र ा ा _ _ _ _ _ _ _ \n",
            "ा ा ा र \n",
            "ा ा र ् र _ _ _ _ _ _ _ _ _ \n",
            "ा ा ा ा \n",
            "ा ा ा ा ा ा \n",
            "र र र र र \n",
            "् र र \n",
            "ा ् ा ा ा _ _ _ _ \n",
            "र ा र र ा \n",
            "् ा ा \n",
            "ा ा ा ा ा ् _ ा _ _ _ \n",
            "ा ा र र ा ा _ \n",
            "\n",
            "[STATUS] Batch 41/656 complete! Batch Loss: 0.5056592226028442\n",
            "0.8846774\n",
            "41\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 42 optimized output for Epoch 0:\n",
            "ा र र ा र \n",
            "र र ा ा \n",
            "र र र र ा _ \n",
            "र र र र ा _ र \n",
            "ा ा ा ा ा ा ् र \n",
            "ा र ् र ा ा \n",
            "ा ा ा ा ा ा _ \n",
            "ा ा ् ा \n",
            "ा ा ा ा र ा _ र _ _ _ _ \n",
            "र र र र ा _ _ _ _ \n",
            "र ा र ा ा \n",
            "ा ा ा ा _ _ _ _ _ _ _ \n",
            "ा ा र ा ा ् र \n",
            "ा ा ा ा ा _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "र ् र र ा \n",
            "र र र ा ा \n",
            "ा र ा \n",
            "र र ा ा ा _ र _ \n",
            "र र र ा ा _ _ \n",
            "र र र ा ा ् _ \n",
            "\n",
            "[STATUS] Batch 42/656 complete! Batch Loss: 0.5116795897483826\n",
            "0.88387096\n",
            "42\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 43 optimized output for Epoch 0:\n",
            "र र र ा ा _ _ \n",
            "ा र र र ा ा _ _ ा _ _ \n",
            "र र र र र ा _ र \n",
            "र र र र ा \n",
            "ा ा ा ा ा ा _ _ _ _ _ \n",
            "र र र ा ा ा \n",
            "ा ् र र ा ा ा \n",
            "र ् र र \n",
            "ा ा ा ा ा _ _ ा _ \n",
            "ा ् र र र _ _ _ _ _ \n",
            "ा र र ् र \n",
            "र र र र \n",
            "र ा ा ा \n",
            "र र ् र ् र _ _ \n",
            "र र ् र र ा ा \n",
            "र र र _ ा ा \n",
            "र र र ् र _ _ \n",
            "र ा ा ा ा _ _ _ र \n",
            "ा ा र ा ा र \n",
            "र र ् ा ा ा _ \n",
            "\n",
            "[STATUS] Batch 43/656 complete! Batch Loss: 0.5406680703163147\n",
            "0.87741935\n",
            "43\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 44 optimized output for Epoch 0:\n",
            "र ा ा ा ा \n",
            "र ा ा ् ा ा ा _ _ _ _ _ \n",
            "ा र र ा \n",
            "र र र र ा \n",
            "ा र ् र ा \n",
            "र र ् र ा ा र ् \n",
            "ा ् ा ा ा ा _ _ _ _ _ \n",
            "ा र र र ा ा \n",
            "र र र ा ् ा \n",
            "र ा ा ा ा _ _ _ \n",
            "र र र ् र र \n",
            "र ा र ् ा _ _ _ _ ा \n",
            "र ् र र ा \n",
            "ा ा ा ा ा ा ा _ _ \n",
            "र र र ा \n",
            "ा र र र \n",
            "ा ा र ा ा \n",
            "र ा र ा \n",
            "ा ा ा ा ा ा \n",
            "र ा ा ा ा _ _ _ \n",
            "\n",
            "[STATUS] Batch 44/656 complete! Batch Loss: 0.5381860136985779\n",
            "0.87580645\n",
            "44\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 45 optimized output for Epoch 0:\n",
            "ा ा ा ् ा ा ा \n",
            "र र ् र ा ा \n",
            "ा ा ा ा ् _ _ _ _ _ _ _ _ \n",
            "ा ा ा ा ा ा \n",
            "र र ा ा ा ा ा ा \n",
            "र र ा र ा \n",
            "र ा ा ा ा _ _ _ _ ा _ \n",
            "ा ा ा ा \n",
            "ा ा ा ् ा ा ा _ \n",
            "ा ा ा ा _ _ _ _ _ \n",
            "र र र र ा _ _ \n",
            "र ा र ा ा ा \n",
            "र र र ा ा \n",
            "र र र ् \n",
            "र ा ् ा ा ा ा \n",
            "ा ा र ा ा ा \n",
            "र ् र र ा ा _ ा _ _ \n",
            "र ा ा ा ा ा ा ा \n",
            "ा र ा ा ा \n",
            "र ा ् ा ा ा _ _ \n",
            "\n",
            "[STATUS] Batch 45/656 complete! Batch Loss: 0.5374718308448792\n",
            "0.87580645\n",
            "45\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 46 optimized output for Epoch 0:\n",
            "र र र ा ा र ा \n",
            "र ा ा ा _ _ ा _ \n",
            "ा ा ा र ा \n",
            "र ा ा ा ा ा \n",
            "र ा ा ा ा \n",
            "र ा ा ा \n",
            "ा ा ा ा ा ा र _ _ \n",
            "र ा ा ा ा \n",
            "ा ा ा ा _ _ ा _ \n",
            "ा ा ् ा ा ा ा \n",
            "ा ा ा ा ा _ _ ा _ _ _ \n",
            "र ा ा ा \n",
            "र ा ा ा ा \n",
            "र र ् ा ा \n",
            "ा ा ा ा र ा _ _ \n",
            "र ा ा ा ा ा \n",
            "र र ा ा _ _ \n",
            "ा र ा ा ा ा ा \n",
            "र ा ा र ा _ _ _ \n",
            "र ् र ा र _ _ _ _ \n",
            "\n",
            "[STATUS] Batch 46/656 complete! Batch Loss: 0.4730813801288605\n",
            "0.88709676\n",
            "46\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 47 optimized output for Epoch 0:\n",
            "ा ा ा ा _ ा ा ा _ _ \n",
            "र र ा \n",
            "र र र ा ा \n",
            "र र ् र ा \n",
            "र ा ा ा \n",
            "ा र ा ा ा ् _ \n",
            "र ा ् ा ा ा र \n",
            "र ा ा ा ा ा ा \n",
            "ा ा ा ा ा _ _ ा र \n",
            "र र ा _ ा ा ा ा ा \n",
            "र र र ा ा \n",
            "र ा ा ा ा ा \n",
            "ा ा ा ा ा _ _ _ _ _ _ र _ \n",
            "र ् र ा र _ _ ा _ \n",
            "ा ा ा ा ा ा र \n",
            "र ा र ा ा \n",
            "ा ा र ा _ ा ा ा _ _ _ र _ \n",
            "र र ा ा ा \n",
            "ा ा ा ् ा ा ा _ _ ा _ _ _ _ _ _ \n",
            "र र ा ा ा \n",
            "\n",
            "[STATUS] Batch 47/656 complete! Batch Loss: 0.5299453139305115\n",
            "0.87419355\n",
            "47\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 48 optimized output for Epoch 0:\n",
            "ा ा ा ा _ _ ् र ा _ _ _ _ _ _ _ _ _ _ _ \n",
            "ा ा ा ा ा ा \n",
            "र र ा ा ा ा \n",
            "ा र ा ा ा ा _ ा _ _ _ र _ _ _ _ ा \n",
            "र र ् र ा ा र ा \n",
            "र ा र र ा \n",
            "र ा र र ा \n",
            "र ा ा ा ा ा र _ _ ् \n",
            "र र ा ा ा ा ् \n",
            "ा र ा र ् ा ा \n",
            "र र र ा ा र \n",
            "र र ा ा ा \n",
            "र ा ा ा र ा _ _ ् _ ् र _ _ _ _ _ र \n",
            "र ा ा ् ा ा ा \n",
            "र ा ा ा ा ् र _ _ _ \n",
            "र र र र \n",
            "र ा ा ा ा \n",
            "र र ा ा ा ा ा _ \n",
            "ा ा ा ा ा _ _ _ _ _ _ _ \n",
            "र र ा ा ा ा \n",
            "\n",
            "[STATUS] Batch 48/656 complete! Batch Loss: 0.568213701248169\n",
            "0.86774194\n",
            "48\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 49 optimized output for Epoch 0:\n",
            "र र ् ा ा _ _ _ _ _ _ _ \n",
            "र र र ा ा ा \n",
            "र ा र \n",
            "र ा ा ा ा ा ा ् \n",
            "र र ा र ा \n",
            "ा र ा ा ा ा ा ा \n",
            "र र र ा ा \n",
            "र र ा ् ा र \n",
            "र र ् र ा ् ा ा \n",
            "म र र ा \n",
            "र र र र ा ् ा \n",
            "र र ा _ ा ा _ _ _ _ ् _ _ _ \n",
            "र र ा र \n",
            "र र र र ् ा ा \n",
            "र र ा ् ा ा ा _ _ र _ ् _ \n",
            "र ा ा ा \n",
            "र ा र \n",
            "ा ् ा ा ा ा _ ा ा _ ा _ _ _ ् _ _ \n",
            "र र ा ा ा ा र ा _ र _ _ \n",
            "र ा ा ा ा ा ा ा \n",
            "\n",
            "[STATUS] Batch 49/656 complete! Batch Loss: 0.47126445174217224\n",
            "0.90403223\n",
            "49\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 50 optimized output for Epoch 0:\n",
            "र ् र र ा _ ा ् _ ा _ _ \n",
            "र र ् र र ा ा ा _ \n",
            "र र ा ा ा ा \n",
            "र र र ा ा ा ा \n",
            "र र ् र \n",
            "र ा र ा ा र ् ा \n",
            "र र र ा ा ा र \n",
            "र र र ा \n",
            "र ा र ा ा ा \n",
            "र र ा ा ा _ _ _ ा \n",
            "र र ् ा ा ा ा _ _ _ ् _ _ _ \n",
            "ा र ् ा ा _ ा _ ् _ ् _ _ \n",
            "ा ा ा _ ा ् र _ _ _ _ _ _ _ _ _ _ ा _ _ _ _ _ _ _ _ _ _ _ र _ _ ा ा _ ा \n",
            "ा ा ा ा ा ा _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "र र र ा ा ा \n",
            "र र र र _ ा ा \n",
            "र ् र र र _ _ _ _ _ _ _ _ _ र ् _ _ \n",
            "र र ा ा ा \n",
            "र र र र ा \n",
            "र र र ा ा ा \n",
            "\n",
            "[STATUS] Batch 50/656 complete! Batch Loss: 0.5936797857284546\n",
            "0.87741935\n",
            "50\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 51 optimized output for Epoch 0:\n",
            "र र र ा र \n",
            "स ा ा ा ा ा ा \n",
            "र र र र ा \n",
            "र ा ा ा ा ा _ _ _ _ _ _ _ र _ _ _ ा _ \n",
            "र र ा र ा \n",
            "र ा ा ा _ ा ा ा _ _ ा ा ् _ ा \n",
            "र र ा ् ा ् ा ् ा र \n",
            "र र र ा ा र ् \n",
            "र ा ा ा ा ा ा ा \n",
            "र र र ा र ा र \n",
            "र र ् र ा र ा \n",
            "र ा र ा ा \n",
            "स र र ा _ ा ा ् र ा \n",
            "म र ा ा ा ा ा \n",
            "् ा \n",
            "ा ा ा ा _ ा ा _ ् _ ा \n",
            "र र र र _ _ _ ा र ् _ ा _ ् _ _ _ _ _ _ _ _ _ _ _ ् _ ् र _ _ _ \n",
            "म र ् र \n",
            "र र ् र ा _ र ा \n",
            "र र र ा ् ा ा \n",
            "\n",
            "[STATUS] Batch 51/656 complete! Batch Loss: 0.5070177912712097\n",
            "0.8943548\n",
            "51\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 52 optimized output for Epoch 0:\n",
            "र ा र ा ा ा ा _ _ _ _ ा _ र ् _ _ \n",
            "र र र ा ा ा ा \n",
            "र र ा र ् \n",
            "र ा र ा ा ा \n",
            "र र ा ् र \n",
            "स र र ा ा \n",
            "स र र ा ा \n",
            "र ा र र ा \n",
            "र र ् र ा _ ा ा ् \n",
            "ा ा ा ा ा ा ् _ _ _ _ _ _ ा _ ा _ _ _ _ _ ् \n",
            "र र र र \n",
            "र र र र ा _ ा र ् \n",
            "र र ा ा _ ा ा _ _ \n",
            "र र र _ र _ _ _ _ ् र _ _ _ ् _ र _ _ _ _ _ र ् _ _ _ _ _ _ र _ _ _ _ _ ् _ ् र _ _ _ _ _ _ र _ _ \n",
            "र र र ा _ ा ा र ् _ \n",
            "र ् ा र ा \n",
            "र स ् ् \n",
            "र ा ा ा ा \n",
            "र ा ा ा ा ा र _ ा ् \n",
            "म र र \n",
            "\n",
            "[STATUS] Batch 52/656 complete! Batch Loss: 0.6473842263221741\n",
            "0.8604839\n",
            "52\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 53 optimized output for Epoch 0:\n",
            "म र र \n",
            "र ा र ् \n",
            "र र र \n",
            "र र ् र \n",
            "म र र र \n",
            "र ा र \n",
            "र र र ा \n",
            "र र र र ा \n",
            "र र ा ा ा ् र \n",
            "म र \n",
            "र र र र _ ा ा _ \n",
            "र ा र र र र ् _ _ _ _ _ र _ _ ् र ा _ _ _ _ _ _ _ _ ् _ ा ा _ _ _ _ _ ् \n",
            "र र ा र \n",
            "र र र र \n",
            "र र र \n",
            "र र र \n",
            "र र र र ा _ ा \n",
            "म र र ा \n",
            "र र र र र र ् _ _ _ _ र ् _ _ _ _ _ _ _ _ र ् ् ा _ \n",
            "र र र र _ \n",
            "\n",
            "[STATUS] Batch 53/656 complete! Batch Loss: 0.5426473617553711\n",
            "0.87741935\n",
            "53\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 54 optimized output for Epoch 0:\n",
            "र र र ा \n",
            "र र र ा ा _ \n",
            "र र र र \n",
            "स र र र _ \n",
            "र ा \n",
            "र र र र र _ ् \n",
            "र र र ् र _ ा \n",
            "र र \n",
            "र म र \n",
            "र र ा \n",
            "र र ् र ा ा ् ा _ \n",
            "म र र ा \n",
            "र र ा \n",
            "स ् र र ् \n",
            "स ा र ा _ ् \n",
            "र र र ् \n",
            "र ् र \n",
            "र स \n",
            "र ् र र \n",
            "र ा र \n",
            "\n",
            "[STATUS] Batch 54/656 complete! Batch Loss: 0.48775970935821533\n",
            "0.88225806\n",
            "54\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 55 optimized output for Epoch 0:\n",
            "ल ा ा ा \n",
            "र र ् \n",
            "र ा ा \n",
            "र र र ् \n",
            "स र र \n",
            "र र र ् र \n",
            "र र ् र \n",
            "र र र ा ा ा \n",
            "र र र र ् \n",
            "म र र र ा \n",
            "र र ा र ा \n",
            "र र र ा ा \n",
            "म र र \n",
            "म र ा ा \n",
            "र र ् र \n",
            "स ् र ा \n",
            "र र र ा \n",
            "स र ् र \n",
            "म र र \n",
            "र ् र ा र _ \n",
            "\n",
            "[STATUS] Batch 55/656 complete! Batch Loss: 0.44083231687545776\n",
            "0.89032257\n",
            "55\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 56 optimized output for Epoch 0:\n",
            "र र र र ा \n",
            "र र र ् \n",
            "र ् र \n",
            "र र र र _ र \n",
            "र ा \n",
            "र ा \n",
            "म र र \n",
            "र र ा ा ा \n",
            "स र ा र ा \n",
            "र स र र \n",
            "स र ा ा ा \n",
            "र र र ा ा र _ _ _ _ ा ा _ _ _ _ _ _ _ _ _ ा ् ा \n",
            "स र र \n",
            "र र ा ् र \n",
            "र र ् \n",
            "र ा ा \n",
            "र र र \n",
            "र र र ् \n",
            "र र र र ा _ _ ् ् _ ् र ् ् ् _ ा _ ा \n",
            "र र र \n",
            "\n",
            "[STATUS] Batch 56/656 complete! Batch Loss: 0.46489518880844116\n",
            "0.89193547\n",
            "56\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 57 optimized output for Epoch 0:\n",
            "म र र \n",
            "र र र ् र _ ् ् \n",
            "स र र \n",
            "स र र ा ा ा \n",
            "र र ा \n",
            "र र र ा \n",
            "र र र ् ् _ ा ् \n",
            "स ा र ा \n",
            "र ् र र ा \n",
            "म र र र ् \n",
            "र र र \n",
            "म र र ् \n",
            "स ् र ा ा \n",
            "र र र \n",
            "र र र ् ् _ ् ् ा \n",
            "र र र ा \n",
            "र र र ा ा \n",
            "र र ् र ा \n",
            "र र र र \n",
            "र र ा र ा ा ा ् ा \n",
            "\n",
            "[STATUS] Batch 57/656 complete! Batch Loss: 0.42021021246910095\n",
            "0.90645164\n",
            "57\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 58 optimized output for Epoch 0:\n",
            "र र र र \n",
            "म ल ा ा ा \n",
            "र र र \n",
            "र ् र ् र _ _ _ _ ् _ ् _ _ _ _ ् ् ् ् _ _ \n",
            "र ा ा ा ा \n",
            "र ् र र र ा ् _ _ _ _ _ _ _ ा र ् ् ् ् ् \n",
            "म र ा ा ा ा \n",
            "स र ा ा ा \n",
            "स ा ा ा \n",
            "र ् र र ा ा _ ा ा ् ् ् ् _ ा \n",
            "र ा र र \n",
            "र ा र ा ा \n",
            "र र र ा ा ा _ ् ा ् ा \n",
            "र र ा ा _ ा ा \n",
            "र र र _ र _ _ _ _ _ _ _ ् _ _ _ _ ् _ _ _ \n",
            "ल र ा ा ा ा \n",
            "र र र ा र \n",
            "र र ा ा ा र ा \n",
            "र र ् र ा र _ _ _ ् _ _ _ _ _ _ _ _ ् ् \n",
            "र र र ा ा _ ा ा ् ा ् ् \n",
            "\n",
            "[STATUS] Batch 58/656 complete! Batch Loss: 0.5579380393028259\n",
            "0.87419355\n",
            "58\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 59 optimized output for Epoch 0:\n",
            "स र ा ा \n",
            "र र ा ा ा \n",
            "र र र र \n",
            "र र र ् र _ ा ् ् ा र ् ् \n",
            "र ा ा ा ा ् र \n",
            "ल र ल ा \n",
            "र र र र _ _ _ र ् _ _ र ा \n",
            "र र ा \n",
            "स र र ा ा ा ा ा ा ा \n",
            "म र ा र ा ा \n",
            "र ा ा ा ा ा ा ा ् \n",
            "र र र ा ा \n",
            "र ् र र ा \n",
            "म र ा ा \n",
            "र ा ा ा _ ा ा र ् ् र \n",
            "र र र ा ा ा \n",
            "र ा र ा _ ा ा ा ा ा ा ् \n",
            "र ् र ा ् ा _ ् ा ् ् ् \n",
            "म ा ा ल ा ा ा \n",
            "र ा र ् ा \n",
            "\n",
            "[STATUS] Batch 59/656 complete! Batch Loss: 0.40432384610176086\n",
            "0.9153226\n",
            "59\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 60 optimized output for Epoch 0:\n",
            "र र ् र ् ् ा र ् र \n",
            "स ा ा र \n",
            "र र ा ् ा ् \n",
            "स ा ा ा ा \n",
            "म र ा ा ा ा न \n",
            "र र र ा _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "र र ् र ् र _ _ ् र ् ् र \n",
            "र ा र ा ा ा ् ा \n",
            "स र र ा \n",
            "र र ा ् ् ा _ _ ् ा ् ् ् ् ् \n",
            "र र ् ् ् ् _ ् न \n",
            "म ा ् ा ् ा ् र \n",
            "र र र ् ् ा ा ा _ ् _ ् _ \n",
            "र र ा र ा ् \n",
            "र र ा \n",
            "स ा न \n",
            "स र ा ल ा \n",
            "र र ् ् ा \n",
            "स र ा ा ा \n",
            "स र ा ा \n",
            "\n",
            "[STATUS] Batch 60/656 complete! Batch Loss: 0.40642836689949036\n",
            "0.91290325\n",
            "60\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 61 optimized output for Epoch 0:\n",
            "र र न ा \n",
            "र ा ा ् ् ् ् ् _ _ _ ् र ् ् ् ् ् ् न \n",
            "र ा ा ा \n",
            "र न ा ा ा \n",
            "र र ा र ल ् ् र \n",
            "र ा ा ल ा \n",
            "र ् र र र \n",
            "स ल ा र \n",
            "म र र र \n",
            "र र र र ा _ ् _ ् ् ् ् ् ् \n",
            "र स ् र ा न _ ् _ ् ् र \n",
            "र ा ा ा र ा \n",
            "र र ा ा \n",
            "स र र ा ा \n",
            "र र ा ् र \n",
            "र र र ा र ् ् _ _ ् ् ा ् _ \n",
            "र र र ा ा ल \n",
            "र म र र \n",
            "र र र ा न ा _ ् ् \n",
            "र ् र ा ् ् ् \n",
            "\n",
            "[STATUS] Batch 61/656 complete! Batch Loss: 0.4214560091495514\n",
            "0.91129035\n",
            "61\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 62 optimized output for Epoch 0:\n",
            "र र र _ र ा ा \n",
            "र र र \n",
            "स र र ् \n",
            "र र ् न ि _ _ र ् ् ् ा \n",
            "र र र र र ् ् ा र ा _ न न ा ा _ \n",
            "र र र \n",
            "र र ् र ा \n",
            "र र र ा ल \n",
            "र स ् र ा ा \n",
            "र ् र र ल \n",
            "र ा ल \n",
            "र र र ् र र ् ् _ ा _ र ि _ र ् ा र \n",
            "र ा ा ा \n",
            "र र र ा र \n",
            "र र र र ा \n",
            "र र र \n",
            "र ा र ा _ _ र ् ् _ _ _ ् _ न \n",
            "र र र ा ा ् _ _ _ र ् ् ा \n",
            "र र र र र \n",
            "म ा र ् ् ् ा \n",
            "\n",
            "[STATUS] Batch 62/656 complete! Batch Loss: 0.437221884727478\n",
            "0.91451615\n",
            "62\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 63 optimized output for Epoch 0:\n",
            "र र र र ् \n",
            "म ा न ा \n",
            "ल र न ् ् _ _ ् \n",
            "र र र र ् ् _ _ र ् _ ् \n",
            "स र ा \n",
            "र र र र ा ् \n",
            "र ल र ा र \n",
            "र र र ा ा न _ ि ् \n",
            "र र ् र र ल _ ् \n",
            "र स र \n",
            "र ा र र ा _ _ _ _ ि _ ् _ _ ् \n",
            "र र र ि र ् _ _ _ _ ् ् ि र \n",
            "र र र र ा र \n",
            "र र न \n",
            "र र ् र ा \n",
            "र ल ा र ा \n",
            "र र र र ् ् _ \n",
            "म ा न \n",
            "र र र र \n",
            "म ा ा ा \n",
            "\n",
            "[STATUS] Batch 63/656 complete! Batch Loss: 0.4685403108596802\n",
            "0.8967742\n",
            "63\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 64 optimized output for Epoch 0:\n",
            "र र र र _ \n",
            "र र ा ् ा ा र \n",
            "र र र ा \n",
            "र र र र र \n",
            "र ा र र \n",
            "र र र र _ र _ र \n",
            "र र र ा _ ा \n",
            "र र र ् र _ _ ा र ् ् _ ् \n",
            "र ् र र _ र ा \n",
            "र र र \n",
            "र र ् र र ् \n",
            "र ् र र र _ \n",
            "र र ल ् ् ा \n",
            "र र र र \n",
            "र र ् र ि \n",
            "र ल र ा ा \n",
            "र र र ा \n",
            "र र र ल \n",
            "र र र ् र ा \n",
            "र ा र र \n",
            "\n",
            "[STATUS] Batch 64/656 complete! Batch Loss: 0.4169316589832306\n",
            "0.9016129\n",
            "64\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 65 optimized output for Epoch 0:\n",
            "र र र र र ा \n",
            "र र र ा ा \n",
            "र र र ि र ि _ _ _ _ _ ् _ _ _ न ा ् _ \n",
            "र र र र र र _ ा \n",
            "र र र र र _ ा \n",
            "र र र _ _ ् ् _ र _ ् \n",
            "र र र र ा \n",
            "र र र ् ् \n",
            "र र ा ा र \n",
            "र र र ा र ा \n",
            "र ा र ् \n",
            "र र ् र ा \n",
            "र र र र र ा \n",
            "म ा र ् \n",
            "र र र र ा ल ि \n",
            "र र र ा ् र \n",
            "र र र र ् न \n",
            "र र र र र \n",
            "र र न \n",
            "र र र र ् \n",
            "\n",
            "[STATUS] Batch 65/656 complete! Batch Loss: 0.44047147035598755\n",
            "0.90403223\n",
            "65\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 66 optimized output for Epoch 0:\n",
            "र र ा ा ा \n",
            "र र र र _ _ र _ _ _ र \n",
            "र ा ा ा ा \n",
            "र ा र ा न \n",
            "म र र र र ल \n",
            "र र र र र \n",
            "र र र ा ा \n",
            "र र ा र ा \n",
            "र र ा र ा \n",
            "र ् र र र र _ _ _ न ् र \n",
            "र र र र र \n",
            "र ा र र _ _ _ _ _ ा _ _ _ ा \n",
            "र र र ा र र _ _ _ न _ _ ् ि _ _ _ ् र \n",
            "र र र _ र ि र र ् ् ् ् ् \n",
            "र र र र र ा \n",
            "र र र र र ् र ा र ा _ न _ र न ा _ ा \n",
            "र र र ा _ न ा \n",
            "र ा र र न \n",
            "र र र ि ा _ ा ा न \n",
            "र र र _ र र ् ् \n",
            "\n",
            "[STATUS] Batch 66/656 complete! Batch Loss: 0.4488649368286133\n",
            "0.90806454\n",
            "66\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 67 optimized output for Epoch 0:\n",
            "र र ् र ा ा \n",
            "र र र _ _ र _ _ _ _ _ _ _ र ् र ा न \n",
            "ल र ् र ा ा \n",
            "र र र ा ा ा \n",
            "स ् र ा र र ा र \n",
            "र र र र \n",
            "र र र ि र ा \n",
            "र र र र र र _ _ _ _ _ ् र ् र र र \n",
            "र र र र _ र _ _ र _ \n",
            "र र ा र \n",
            "र र र ा \n",
            "र र र \n",
            "र र ् र र र _ _ _ _ ा _ _ र \n",
            "र र र र _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "र र र र \n",
            "र र र र र ा _ ा _ _ _ र _ _ ् _ _ र ि _ र र ् र \n",
            "र र र र ा ा \n",
            "र र र र ि _ _ _ _ _ _ _ _ ा \n",
            "र र र र _ _ र _ _ _ ् र ि _ \n",
            "र र र र र र \n",
            "\n",
            "[STATUS] Batch 67/656 complete! Batch Loss: 0.5079536437988281\n",
            "0.88870966\n",
            "67\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 68 optimized output for Epoch 0:\n",
            "र र र ् र र _ _ _ ् _ _ र ि _ र \n",
            "र र र र र \n",
            "र र र र \n",
            "र र र र \n",
            "स र र ा \n",
            "र र र र र \n",
            "र र र र \n",
            "र र र ् र _ _ _ _ _ _ _ र ् र \n",
            "र र ् र \n",
            "र र र र र र न ि _ _ \n",
            "र र र र ा \n",
            "र र र ि र र \n",
            "र र र र र र \n",
            "र ा ा ा _ _ _ _ _ _ _ _ र _ _ _ ् _ _ _ ् _ न _ _ _ ा _ _ _ र _ ि _ _ _ र \n",
            "र र र र \n",
            "र र र र र र ि _ र \n",
            "र र र र र र ् _ _ _ _ _ _ _ _ _ _ _ ् र ा _ ् _ ा \n",
            "र र र र ि र \n",
            "र र र र र _ _ _ _ ् _ ् र \n",
            "र र ा र _ _ _ _ _ _ _ ् _ र \n",
            "\n",
            "[STATUS] Batch 68/656 complete! Batch Loss: 0.5110884308815002\n",
            "0.88225806\n",
            "68\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 69 optimized output for Epoch 0:\n",
            "र र ् र र र \n",
            "र र र र र \n",
            "र र र र र ा _ र \n",
            "र र र र र र र र \n",
            "र र र र र _ _ _ र ि _ \n",
            "ल र ा र ा \n",
            "र र र र ा न ा \n",
            "र ा र र \n",
            "र र र र ् र र र \n",
            "स र र \n",
            "र र र र र र _ _ _ ् र _ _ \n",
            "र र र _ र _ ् र ा _ _ _ \n",
            "र र र _ र _ _ न र \n",
            "र ा ा ् र र _ _ _ न \n",
            "र र र र र ् र र \n",
            "र र र ा र ा ा ा ा \n",
            "ल र र \n",
            "ल र ा र \n",
            "र र र ा ा \n",
            "र र र \n",
            "\n",
            "[STATUS] Batch 69/656 complete! Batch Loss: 0.33938395977020264\n",
            "0.9201613\n",
            "69\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 70 optimized output for Epoch 0:\n",
            "र र र _ _ _ _ _ _ र ा _ \n",
            "र र र र ा _ _ _ _ _ _ ् _ न \n",
            "र र र _ _ ा _ _ _ ा _ _ _ _ ् _ र \n",
            "र र र र ा \n",
            "र र र र र र \n",
            "र र र र र ् _ ा र ा _ _ _ _ ि _ _ र ा _ _ ा ि \n",
            "र र र ा र \n",
            "र र र ा ा र \n",
            "ल र र र न ा \n",
            "र र र र र ् र ा _ _ _ _ _ _ \n",
            "र र र र र र \n",
            "र र र र ा ा \n",
            "म र र ् र र \n",
            "र र र र _ _ ् र र र _ _ ि न ् र _ \n",
            "र र ् र र ् र ा ् \n",
            "र र र ् ा र ा ा ा \n",
            "र ा र ् र \n",
            "र ा ा ा ा \n",
            "र ा र _ र _ र र ा \n",
            "र र ा र र ि र \n",
            "\n",
            "[STATUS] Batch 70/656 complete! Batch Loss: 0.4914867877960205\n",
            "0.8943548\n",
            "70\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 71 optimized output for Epoch 0:\n",
            "र र र ा ा \n",
            "र र र र ा \n",
            "र र र ा \n",
            "र ् र ा ा ा ा \n",
            "र र ् र र ा _ ा ा \n",
            "र ा र र _ _ ् ् ा ा ् र \n",
            "र र र ि _ _ र _ _ _ र न ा \n",
            "र र र र र र _ _ \n",
            "र र र ल ् ा \n",
            "र र र र र ् र ा र ा _ _ ि र ् र _ ा \n",
            "र र र र र ि _ _ _ _ _ ् न \n",
            "र र र ् र _ र _ _ न र ् \n",
            "र र र _ _ _ ् _ _ _ _ _ _ ् _ ् _ _ _ ् र ा _ _ ् \n",
            "र र र र \n",
            "र र ् र र ् र ा \n",
            "र र र र ् ा \n",
            "र ा र ् र ि न _ _ ् न \n",
            "ल ा र _ ा ा ् _ र \n",
            "र ् र र र _ _ ा र ् \n",
            "र र ा ा ् ् \n",
            "\n",
            "[STATUS] Batch 71/656 complete! Batch Loss: 0.5862476229667664\n",
            "0.87258065\n",
            "71\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 72 optimized output for Epoch 0:\n",
            "र र ा ा ा ा \n",
            "र र र _ _ _ _ र ि _ न _ ा ि ् र \n",
            "र ् र ा ा ा _ ा \n",
            "र ा र ् र ा ा \n",
            "र र र ् र ा ा \n",
            "र ा ा ा _ ा ा र \n",
            "र ल र ा \n",
            "म र ा \n",
            "र र ा ा \n",
            "ल र न \n",
            "म र ् ा ा \n",
            "स र र ा ा न ा \n",
            "स र र र _ _ _ ा ा \n",
            "स र ा ा र \n",
            "र र ा ा ा \n",
            "र र र ा \n",
            "स ् र र ा न _ \n",
            "र र र ा \n",
            "र र र ा \n",
            "र र र न \n",
            "\n",
            "[STATUS] Batch 72/656 complete! Batch Loss: 0.3239133656024933\n",
            "0.9314516\n",
            "72\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 73 optimized output for Epoch 0:\n",
            "र ा र ा र ा _ ् \n",
            "ल ा ा र \n",
            "र ा ा ा \n",
            "र ा र न \n",
            "र ा ा र \n",
            "म ा ल ा ा \n",
            "र र र ा ा \n",
            "र र ् न र _ र ा ा र ् ् \n",
            "र र ा ा ा ा ा ् _ _ ा \n",
            "म र न ा \n",
            "म न ा ा \n",
            "र ा ा ा \n",
            "र ा ा ा ा र \n",
            "र र र ् र _ ् ् _ ा ् ् \n",
            "स म ् ा ा ा \n",
            "म र न ा \n",
            "म ा \n",
            "म ा ा ् ा \n",
            "र र र ् र ् ् ् ् र ा \n",
            "म ा ा ् ा \n",
            "\n",
            "[STATUS] Batch 73/656 complete! Batch Loss: 0.36132144927978516\n",
            "0.9233871\n",
            "73\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 74 optimized output for Epoch 0:\n",
            "र ा ा न ा _ _ _ ् ् ् ् ् ् न \n",
            "म ा ा ा ा न ् \n",
            "म र ा ल _ ा ा ा ा \n",
            "र र ा ा \n",
            "म ा ा ा \n",
            "र र न ा \n",
            "म ा ा ल \n",
            "र र न ् न \n",
            "र र र ा ा _ _ _ ् ा _ ् ा न \n",
            "म र र ा ा ा _ _ ् न ा ा र ् ् ा \n",
            "म म ा र ा \n",
            "स ा ा ् ा ् र \n",
            "र र ा र \n",
            "म ा ा ा न \n",
            "र न ् ् ् ् ् ् र _ ् ् \n",
            "ल र ा ् र ा \n",
            "म ल ् ल ा ा \n",
            "म ा र ् ा _ ा ा \n",
            "म ा न \n",
            "र _ र ा _ _ न ् ् ् र _ _ ् ् ् \n",
            "\n",
            "[STATUS] Batch 74/656 complete! Batch Loss: 0.40903475880622864\n",
            "0.9153226\n",
            "74\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 75 optimized output for Epoch 0:\n",
            "म ा ल ा \n",
            "र र र ् _ ् र न ् ् ् ् \n",
            "म ा ा ा र \n",
            "म र र ा \n",
            "स ् र ा न \n",
            "र र ा र ा _ ् ् ् \n",
            "म ा ा ा ा \n",
            "म र र _ ् न _ _ ् र ् ् _ ् न \n",
            "म न ा ा ् र \n",
            "म ा ा न \n",
            "र ् र ् ् ् ् ् _ ् ् ् ् \n",
            "स र ा न ा ा \n",
            "म र र ् न _ ् ् न _ ् ् \n",
            "म ल ा ा ा ा \n",
            "म ा ल ा ा ा \n",
            "म र ् ा ा \n",
            "र र ा ् ा र ् ् \n",
            "र र ा ा ् ् ् र ् ् न \n",
            "र र र ् ् ् ् _ ् न _ ् _ ् ् ् ् ् \n",
            "म र ा ल \n",
            "\n",
            "[STATUS] Batch 75/656 complete! Batch Loss: 0.381798654794693\n",
            "0.9169355\n",
            "75\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 76 optimized output for Epoch 0:\n",
            "म ा ा र \n",
            "र ा ा ा _ ् _ र ा ् ा \n",
            "र र ल ् ् ् _ ् ् ् र \n",
            "र ा र _ _ _ _ ् ् ् न _ ् ् र ् ् न ् र ् ् _ ् ् ् ् _ ् ् ् ् ् न \n",
            "र र र ् ् _ ् ् र ् ् \n",
            "र ा ल ा _ ् ् ् ् र \n",
            "र र ् र _ ् ् ा ् ् \n",
            "म र ा र ा \n",
            "न र ा ा ा ् र \n",
            "म ा ा ा ् ् ् ् \n",
            "म ा ल ा ा ा ा ा \n",
            "ल ा ा ा ा ा \n",
            "स ल \n",
            "र ् र ् ् ् ा ् ् ् ् \n",
            "स र ा ा ा ा ा \n",
            "स ा र न ा \n",
            "म र ा ा ल ा ा \n",
            "म ा न ा न \n",
            "म र ा ा ल ा \n",
            "र ा ा ा ा ा ा ा \n",
            "\n",
            "[STATUS] Batch 76/656 complete! Batch Loss: 0.4040602743625641\n",
            "0.91451615\n",
            "76\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 77 optimized output for Epoch 0:\n",
            "म ि ा ् ा ा ा \n",
            "ल ् र ् ् ा ् ् ा \n",
            "स ् ् ् _ _ ् ् _ _ र ् ् _ _ ् ् ् ् ् _ ् ् ् ् ् ा \n",
            "म र ल ा ् ् ् न \n",
            "म र ् म ा ा \n",
            "म ् र ् ् ी _ ् ् ा र ् ् \n",
            "र र ् ् र ् _ _ ् ् ् ् ् \n",
            "स न ् _ _ _ _ ् ् ् न ् ् ् ् ् ् _ ् ् ् ् ् ् ् \n",
            "स ा म ा ा ल \n",
            "र र र ् ् _ ् ् ् न न \n",
            "म र ा ा र \n",
            "र ा ल ा ् ् ् _ ् ् ् न ् ् ् \n",
            "म र र ा ् ा \n",
            "म म ा ा र \n",
            "म र ा ा ा ल ा \n",
            "म र र ा \n",
            "म ा ा ल ा न \n",
            "म र ा ा ा \n",
            "म र ् ् र \n",
            "र र ् ् ् ् ् ् ् ् ् ् \n",
            "\n",
            "[STATUS] Batch 77/656 complete! Batch Loss: 0.47155216336250305\n",
            "0.8959677\n",
            "77\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 78 optimized output for Epoch 0:\n",
            "र म ा र र _ ् ् ् _ ् ल ् ् ा \n",
            "म र र ा ा \n",
            "म ल ल र \n",
            "म म र म \n",
            "म र ा ा ् र \n",
            "र र र ा न ी _ _ ् ् ा न \n",
            "म म ा ा ा ा \n",
            "र र ि र ा _ _ ् ् _ र ् ् र ् ा ् र \n",
            "म र ि ् ा ा \n",
            "म ल ा ा न \n",
            "स म ा र ् \n",
            "क ा र ् ् ् र ् \n",
            "म म ा ा र \n",
            "म ि ् _ _ _ _ ा _ _ ् ल ा \n",
            "म म ा \n",
            "र ि र ि ् ् _ _ _ र ् ् \n",
            "र ा र र ा _ _ र _ ् ् ् ् _ ् ् ् ् ् न \n",
            "र र ् र _ _ ् _ ि _ ा \n",
            "स र ा र \n",
            "म र ा र \n",
            "\n",
            "[STATUS] Batch 78/656 complete! Batch Loss: 0.3974527418613434\n",
            "0.9169355\n",
            "78\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 79 optimized output for Epoch 0:\n",
            "म ल ल ल ी \n",
            "म र र ् ् _ _ _ ल न \n",
            "म ् र ा ा र \n",
            "म ल ा ा ा \n",
            "ल र र र _ _ _ _ ् ् ् _ न ी _ _ _ _ न _ स ी \n",
            "म र ा र ी ा \n",
            "स र ा न न ् \n",
            "म ल ा ा ि ा ा _ _ \n",
            "म म ा ा ल ा \n",
            "म र ् र ा ा \n",
            "म न म ा ा \n",
            "म ् र ा न ा \n",
            "म ल स ा म ा \n",
            "म ि ा ् ् ा \n",
            "म ा ा ा ा ा \n",
            "म स ् म ा \n",
            "स र ् ् र _ _ _ _ ा स ् ् न र ् स \n",
            "म ा न ा \n",
            "म र म ् ् _ _ ी न \n",
            "म र र ा न ् न \n",
            "\n",
            "[STATUS] Batch 79/656 complete! Batch Loss: 0.4081747531890869\n",
            "0.9201613\n",
            "79\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 80 optimized output for Epoch 0:\n",
            "म म र ् र न ा \n",
            "र र न ि _ र ् _ ि _ _ _ _ _ _ _ स ् _ _ _ _ _ ् ल ि _ ा \n",
            "म ल ल ा र \n",
            "म म र ि \n",
            "म ि र र \n",
            "ल ल ल र \n",
            "म ि ा ा ल ा \n",
            "म म ा म \n",
            "म म ल न \n",
            "म र ि र र ् स _ _ ् _ ि \n",
            "ल ल क _ ा _ ल ा \n",
            "म र ि र ा ल र \n",
            "र र ् र _ _ न _ _ _ ् _ ी र \n",
            "म म ल ा ल \n",
            "र र र ा ा र ् \n",
            "म ् र ा ा न _ \n",
            "र ि ल _ _ _ न _ _ _ _ _ _ _ _ _ _ _ ् _ _ न ि \n",
            "म ि क र ल ल र \n",
            "म ि र ा _ _ ि ल न _ _ ी _ _ स \n",
            "न ा ा ि र _ _ _ स न \n",
            "\n",
            "[STATUS] Batch 80/656 complete! Batch Loss: 0.4715898931026459\n",
            "0.91290325\n",
            "80\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 81 optimized output for Epoch 0:\n",
            "म ि म ् म ी _ \n",
            "म म क ा \n",
            "म म क ा न ् \n",
            "म म न ि ा ा \n",
            "र र र _ _ _ _ र _ _ ि _ स _ र ् _ \n",
            "र ा म ा ी र \n",
            "म म ि ा ा \n",
            "ल ा _ र ल स ् ा \n",
            "म र _ _ ा _ _ _ _ र \n",
            "म क ा र ् ा \n",
            "म र र ा र ा \n",
            "म ा र ा \n",
            "म म र ा \n",
            "म र र र ् \n",
            "म ा र ा \n",
            "स ा ा न \n",
            "म म ् र र र ि ् ा \n",
            "म ा र ा \n",
            "म र ा \n",
            "म ा र ा \n",
            "\n",
            "[STATUS] Batch 81/656 complete! Batch Loss: 0.3032975196838379\n",
            "0.9451613\n",
            "81\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 82 optimized output for Epoch 0:\n",
            "म र ा \n",
            "ब र क ि _ _ _ ा _ ा _ _ _ _ ि _ _ र ा _ ा \n",
            "न म र ल ा ल \n",
            "क ् ल ि ा ा र ् \n",
            "म म ् र ा ा \n",
            "म ि र ा _ _ _ _ ् _ ा न \n",
            "म र ा न _ _ _ र ल ा _ _ स \n",
            "म ा ा ा ा र ् \n",
            "स र र ा र ् र ि \n",
            "र ि र ा _ _ _ _ न ा _ _ _ _ ा न \n",
            "म ् र र _ _ क ् \n",
            "न ् र _ _ _ ् _ ् र ि _ _ ् स _ _ ् र ि _ ् _ ि _ न \n",
            "म र ा न ी _ _ _ _ _ _ न ा \n",
            "म ा न ा ल \n",
            "र न र _ _ _ ् _ _ _ _ र ि _ र _ ा _ र \n",
            "म म ल क ा र \n",
            "म ा र ् क _ _ _ क ् क र \n",
            "क र ् क र र \n",
            "म ल ल ी ल ् ल ् \n",
            "स ा र र _ _ _ _ _ _ _ र _ _ _ ल ा _ \n",
            "\n",
            "[STATUS] Batch 82/656 complete! Batch Loss: 0.48852312564849854\n",
            "0.908871\n",
            "82\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 83 optimized output for Epoch 0:\n",
            "र र न ि _ र ् _ ि _ _ _ _ _ _ _ र ् _ ि _ _ _ \n",
            "क ् र ि र ् र _ ल _ _ ि क \n",
            "म र क ा \n",
            "म र र ् र _ _ र ् _ \n",
            "र र र _ _ ् _ ा र ा _ _ ा _ ा _ _ _ _ र ी _ _ ी \n",
            "क र र ् र ी र न ा \n",
            "र र र _ _ ् _ ा र ा _ _ ि _ र _ ा _ स ा _ ि _ \n",
            "म र ् र र \n",
            "म म र \n",
            "म ि र ् र र र र ् _ \n",
            "स र ल ि र _ _ _ र _ ा न \n",
            "म ि र ा \n",
            "र ि र ा र ् _ _ _ _ _ _ _ ल \n",
            "र र न ा \n",
            "म ा र र \n",
            "न र र म ि _ ा _ _ _ _ र ी \n",
            "ल ि र _ न ा र ् _ _ _ _ _ _ ि _ न ् स ी \n",
            "म म र र _ न ा ा ि र \n",
            "म म क ् ा ि \n",
            "म ा ा ा \n",
            "\n",
            "[STATUS] Batch 83/656 complete! Batch Loss: 0.46794039011001587\n",
            "0.91774195\n",
            "83\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 84 optimized output for Epoch 0:\n",
            "क र ल ा ा \n",
            "क क _ _ ा _ र _ _ _ _ ी _ _ ी \n",
            "म र क ा \n",
            "क क _ _ _ _ _ _ _ _ _ _ \n",
            "म र म ि क ा \n",
            "म ि र ा ा \n",
            "स र _ स ा ल _ _ ा _ \n",
            "ब ा र ् र _ र र _ न _ _ ् र _ _ _ स \n",
            "म न म ा ल _ _ ि _ ा र \n",
            "ब ् र र ् र र _ _ ् र \n",
            "म ि र ा न \n",
            "म र म _ _ र _ _ _ _ _ _ _ ि स ् _ \n",
            "स र र र ् र _ _ _ ् र _ न _ ि क ल \n",
            "स र स ा _ _ _ _ _ न र ल \n",
            "म क र ा ा \n",
            "म क र र \n",
            "म र ् न ् ा \n",
            "र र न _ _ _ _ _ _ ् _ _ _ _ न _ _ ् _ _ र ी _ _ ् र ा _ _ \n",
            "म ् र र र \n",
            "म र ा ा न \n",
            "\n",
            "[STATUS] Batch 84/656 complete! Batch Loss: 0.4257205128669739\n",
            "0.91774195\n",
            "84\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 85 optimized output for Epoch 0:\n",
            "क ा र ा र _ _ ् र ा ् ा \n",
            "म र ि _ _ ा ा न \n",
            "र र म _ न ् _ _ _ ि _ ् र _ र _ _ ् र ा \n",
            "म र ् र ा र \n",
            "स र र र \n",
            "क र ् र र ल _ _ _ _ र ा न \n",
            "म ा र र \n",
            "म क ा ् ा \n",
            "स ा क ल ् र ा \n",
            "क क स ा न ा ल _ _ _ क \n",
            "ल र न ि न ा ् र \n",
            "म म ा ा ा \n",
            "क ा र र र _ _ ि _ ा ा \n",
            "र र र _ ा न _ _ _ ् _ _ न ि क _ ा र \n",
            "म ा र ् र ा ा \n",
            "ब र र _ _ र _ र ि _ र र ा र र \n",
            "क र न म _ _ ी _ र ा \n",
            "क ि र ् ल _ स ् क र _ _ ् र ् र \n",
            "म ि ा ् र र ा न \n",
            "ल ा र ि ा ा ा ् \n",
            "\n",
            "[STATUS] Batch 85/656 complete! Batch Loss: 0.45070967078208923\n",
            "0.908871\n",
            "85\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 86 optimized output for Epoch 0:\n",
            "ब ि ि ल _ _ _ _ _ _ _ _ _ न ा _ ा र \n",
            "म र र र र र \n",
            "म ि ि म \n",
            "क ि क _ _ _ क े \n",
            "क र ल ् र ् र क ा \n",
            "क ि ि ि _ _ _ _ र ् _ \n",
            "म ि ल ् क ि न \n",
            "म म क ा ा \n",
            "क ि र ि न ा \n",
            "क र र _ _ _ _ _ र _ _ \n",
            "क न ् न ा न _ ा र ा र \n",
            "र र न _ ् े _ ल \n",
            "स र ल ा \n",
            "क ल ् र ि ा ा \n",
            "क क े ल ि \n",
            "क क ा ा ा ा ् _ \n",
            "र ा र _ _ _ _ _ _ _ _ _ _ र ि र न _ ् \n",
            "म क ा र र \n",
            "म र ा ा ि \n",
            "ल ा ा र ि ा \n",
            "\n",
            "[STATUS] Batch 86/656 complete! Batch Loss: 0.39012977480888367\n",
            "0.92258066\n",
            "86\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 87 optimized output for Epoch 0:\n",
            "क ु ा र ल ा \n",
            "र र ल ् ् _ _ _ ् _ _ _ ि _ _ _ _ _ _ _ न ् \n",
            "म र र न \n",
            "क ् र र म _ र _ र न \n",
            "म क म ा \n",
            "क ् र ा ा ा \n",
            "क क ल ि ा ् ा \n",
            "न र ल ि ि र \n",
            "क ि र े न _ _ ि स न ् \n",
            "क क क र ा र ा र ् \n",
            "म ि ल न _ म ी र \n",
            "र े ल ् ा \n",
            "क क र ा \n",
            "क ् र ् ि र ा \n",
            "स ु न ् ् र \n",
            "म क ा ् ा न \n",
            "क े र _ ् ा ा \n",
            "र र न े ् ा न ् _ र \n",
            "न र ् ् न ा \n",
            "स ु ् ् र ् \n",
            "\n",
            "[STATUS] Batch 87/656 complete! Batch Loss: 0.3414265811443329\n",
            "0.9354839\n",
            "87\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 88 optimized output for Epoch 0:\n",
            "ल े क \n",
            "क म ि क ा \n",
            "क क ि न ा ा \n",
            "क क म र ् ् ् र \n",
            "क ल स ी \n",
            "क र र ा ा \n",
            "स क ् ् ी \n",
            "क ् र र र ा \n",
            "क क ा ा \n",
            "क ल र ् ् ा \n",
            "क क स \n",
            "क क न र र ा \n",
            "क क े र ा \n",
            "क र ि ् ् र _ _ ा _ \n",
            "म र ् ल ि न _ _ _ न र \n",
            "म क \n",
            "क क न ् _ ् _ _ न _ _ _ स े ् र ा _ र ा \n",
            "क ा र ् र _ _ े _ _ र ि र ल _ _ ् र ् \n",
            "क स ा ा _ ा _ _ र ् न े \n",
            "म ि ि ् े \n",
            "\n",
            "[STATUS] Batch 88/656 complete! Batch Loss: 0.336405873298645\n",
            "0.9379032\n",
            "88\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 89 optimized output for Epoch 0:\n",
            "म े ् र _ _ _ _ _ _ _ _ ् र ् ् _ _ _ स ् र _ _ _ ् ् ् र ् ् ् ् _ _ ् ् े _ र _ _ _ _ _ _ ् _ र _ _ ् ा र ् ् \n",
            "क क र े र े र ् र \n",
            "क ि ् ् र ् ् र ् ् ् \n",
            "स म र \n",
            "क ि र ा न न न र \n",
            "क र ् ् र _ _ ा न न _ _ _ ल ा न \n",
            "क र न ी ् \n",
            "क ा ा े ल \n",
            "क ु र ् र ् \n",
            "क क ि र ् र _ र ् _ ा न \n",
            "क ा र ् र ि न \n",
            "र र न ी _ _ ् े ल ी न र \n",
            "क ल ी न \n",
            "क क र ल \n",
            "क स ् ् े न ् र ा \n",
            "क ि म ा _ _ ् र ् _ _ _ _ र न े ् न _ _ _ र ् ् ् र े न \n",
            "क क ् _ ् ा ा न \n",
            "क ् र ल र \n",
            "स ु र क ् ् ा \n",
            "म क र म \n",
            "\n",
            "[STATUS] Batch 89/656 complete! Batch Loss: 0.4674064815044403\n",
            "0.9104839\n",
            "89\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 90 optimized output for Epoch 0:\n",
            "क ् र ् र ् ी \n",
            "र र र ल _ _ _ _ _ _ _ _ _ _ ् _ _ _ ल _ ् _ \n",
            "क ि र ् र ि र ा न ल ् ल ी \n",
            "क े न े न \n",
            "क े र ् र ् न \n",
            "क ् र ् ् ा \n",
            "र े ् ् र ् र े ् न \n",
            "क ् र _ _ _ _ _ े _ _ _ _ _ र ् ् \n",
            "क र ि ् ् ् र \n",
            "ब र ा _ ् ् म ी \n",
            "क े े _ _ न _ _ न \n",
            "क ् न ि न र ् ् ि र ी _ _ _ _ _ स ् र _ ल _ _ न \n",
            "क ो _ ् र ल ् ा र \n",
            "क ि ् ि र र \n",
            "क ् र ि ् ् र _ _ ् र _ _ ा र ल न \n",
            "र म ा \n",
            "क ् र ् ा न \n",
            "म म ा न न न ी \n",
            "म ा म ा \n",
            "क र _ र _ _ े र ा _ ् _ ् ा _ ् _ \n",
            "\n",
            "[STATUS] Batch 90/656 complete! Batch Loss: 0.432124525308609\n",
            "0.9169355\n",
            "90\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 91 optimized output for Epoch 0:\n",
            "क ् र न ा \n",
            "क स ् र ् र ल \n",
            "ब ल ा र ा ल \n",
            "म ् र ा ा \n",
            "ज ा ् ् ् ी र ् ा ् ् ा \n",
            "क ि स र ा न \n",
            "क ् र ि न \n",
            "ब ् र ि ् _ _ र ् र _ _ ् र ि ् ् र ि र न \n",
            "र े न न \n",
            "क ो स ा ा \n",
            "क ् र ि ् \n",
            "म र ् ् ् न \n",
            "ल ा र ा र ि स \n",
            "क ् र _ _ _ _ _ ् _ _ र ् र ् ् स _ _ े र ि र \n",
            "म म ् म र ा \n",
            "क र र ल े \n",
            "क ् र र न े ् न ल _ _ ् र ् ् _ म ा स ् र र ् स \n",
            "क र र ा _ र ि न ् न ् ् र े \n",
            "क ् क ् र र _ _ _ ् ा न \n",
            "क ि ् ् ल े \n",
            "\n",
            "[STATUS] Batch 91/656 complete! Batch Loss: 0.37213823199272156\n",
            "0.9362903\n",
            "91\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 92 optimized output for Epoch 0:\n",
            "क र ी र ा \n",
            "क स ी न ा _ _ ा न _ _ ा न न ी \n",
            "क क ा ा _ न र ी \n",
            "क ् र ा स ी _ _ र \n",
            "म ि स ् र ा \n",
            "म र ी \n",
            "स ि ् ् न ल _ ् ि ल \n",
            "म ा ा र ि र ा \n",
            "ल ल ् न ा \n",
            "क र ् ् ् ल _ _ न ् न ा न \n",
            "ल ल क \n",
            "क े स न र ि र स _ _ ् _ ि र ा \n",
            "म र े \n",
            "क ो न ी _ _ े ् ट _ स ् ट ् र ि र ् स _ न र ा र ् ् \n",
            "क ् ् ् ी \n",
            "म ल र र \n",
            "क ि _ ् र _ _ ो ल ा \n",
            "ब न न ा र ी \n",
            "क र ् ् न ा \n",
            "क ो र ी _ न र \n",
            "\n",
            "[STATUS] Batch 92/656 complete! Batch Loss: 0.3399128317832947\n",
            "0.94274193\n",
            "92\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 93 optimized output for Epoch 0:\n",
            "क र ् न ी \n",
            "क न े र ी \n",
            "स ि र ् र ् ी \n",
            "स ा ा ् र ी \n",
            "म ु र ् र ् र ा र ा _ र _ ा ल _ ट ट ट ा \n",
            "म ् र र ा ल \n",
            "म र ् ् ी \n",
            "म ि र ा ल ी \n",
            "म ि स ा ल \n",
            "म म ् ् ् ् ि \n",
            "स ा म ल न र _ _ _ ट र \n",
            "क र ी ् ो ल ा \n",
            "स ् र ी _ र ा ् _ र ि र ् र ा ा ल ा _ स र \n",
            "म ि ल ि स े ा ट \n",
            "र ो न ा \n",
            "ब ल ् ् ा र ा \n",
            "म ु र ् र ् र ा र ा _ ा ा _ ल ा _ ट ी \n",
            "स ो र ् र _ स े ् ट _ _ ि ल ि ट \n",
            "क स स ् म ा ा ि र ा \n",
            "म ा म ा _ _ न न ि न ट \n",
            "\n",
            "[STATUS] Batch 93/656 complete! Batch Loss: 0.41218432784080505\n",
            "0.9314516\n",
            "93\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 94 optimized output for Epoch 0:\n",
            "क ल ल ् ल ा \n",
            "र र ् ी ल ा _ र ा ा \n",
            "स ि र _ _ ा र ् र ् ी \n",
            "ल ल ा ल न \n",
            "म ल ा ् स ा न \n",
            "क ि न र े _ _ ी _ _ _ र ट \n",
            "स ि ् ो न े ि र ा \n",
            "म ो ल ि न ी \n",
            "म ो स ् ा ् र ा \n",
            "म ल र ा र \n",
            "स ा न ा _ ा ा न ी \n",
            "स ि ल ा ा ी \n",
            "र ा म _ ल न \n",
            "स ा र न _ _ ा _ _ र \n",
            "र ि र र स ा ा _ \n",
            "स ल ा ी र \n",
            "स ि क ल र ा ा ट _ र ा _ स ि ट ट _ _ न _ स ् _ _ ट ल ल ट _ \n",
            "क ल ा ा ी \n",
            "क ल ा र े \n",
            "न ी न ल ् स _ _ ल ् _ _ ट ट ट र ी \n",
            "\n",
            "[STATUS] Batch 94/656 complete! Batch Loss: 0.35697445273399353\n",
            "0.9395161\n",
            "94\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 95 optimized output for Epoch 0:\n",
            "स ा ा ा ि ा ा ा ा \n",
            "स ा ा ि ा ा ा ा \n",
            "स न ा ् ा ा \n",
            "म म ा न ा \n",
            "क क ा ा ा र \n",
            "प ् र ा र _ _ ि _ _ _ ा \n",
            "व ि ् ् र ा ा ा _ र \n",
            "म े _ _ ् _ ा र _ न ी ी ा \n",
            "ग ल ् ा ा _ _ ा ल \n",
            "स ि र ा \n",
            "क _ ि _ ा ि _ ा _ स _ ा _ \n",
            "स ा ा र ा ा ा ा ा \n",
            "क ं ् ा ल ि ा ा \n",
            "क ल ा ा ा \n",
            "प ् र े म _ _ ा ल \n",
            "क ो क ा _ _ ा ल ा _ _ न ् ट र _ ् र ा ा _ स \n",
            "म ल ् म ा ा ा \n",
            "क ि न े र ा _ _ ा _ ् _ न \n",
            "र ा ा ा ा ट ी \n",
            "क ् र ि स _ स ् _ ि _ \n",
            "\n",
            "[STATUS] Batch 95/656 complete! Batch Loss: 0.3623405992984772\n",
            "0.9346774\n",
            "95\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 96 optimized output for Epoch 0:\n",
            "र र ा ा ल ा \n",
            "क र ा न _ _ ल ा \n",
            "क ल न ा ा _ ा र _ _ ा न ा न \n",
            "क ् ल ी \n",
            "प ा ा र ा _ ल \n",
            "क क ी म ा \n",
            "क क _ _ ि न _ _ _ ी _ र ा ा \n",
            "स ल न ा \n",
            "म ल ा र ा ा ् ट ् र \n",
            "क ा ा ा र ा \n",
            "म ो न र ा ि ा ा \n",
            "क ा ा ा ि ा ा \n",
            "स ् र ् े न ् ् र \n",
            "क े ल ी \n",
            "र े ा \n",
            "म ा ा ा \n",
            "न ् र ा ा ा स ल \n",
            "क ि ा ल ा ा \n",
            "म े न ् स ा \n",
            "क ि ा ा _ _ ा ा ा ा \n",
            "\n",
            "[STATUS] Batch 96/656 complete! Batch Loss: 0.2815079092979431\n",
            "0.95\n",
            "96\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 97 optimized output for Epoch 0:\n",
            "क े म ा \n",
            "क र ् _ _ _ _ _ ् _ न \n",
            "म ल ल े ं ् र \n",
            "म र ् ् ा \n",
            "स ल ् ् ट ि \n",
            "क न ि र _ _ ् ा \n",
            "क े ल ल ा \n",
            "क ि ा ा न _ _ ा _ _ ा ा \n",
            "स ा ा र ा र \n",
            "क ि ल ा ल \n",
            "ग ् र ् ल _ _ _ न _ न \n",
            "क ा ् _ ी _ ल _ _ _ \n",
            "क व र ल ् र ी न _ _ ् _ _ न ि ट ी \n",
            "क ा ा ् र ल ा \n",
            "म ल ी न \n",
            "म ल म ि ा ा \n",
            "क ि ् ् _ ल _ _ ा ् ा ा ा \n",
            "क द म ी \n",
            "क ल न े र _ _ _ ा र ी \n",
            "ज ि न _ _ _ र ि _ \n",
            "\n",
            "[STATUS] Batch 97/656 complete! Batch Loss: 0.32711225748062134\n",
            "0.9379032\n",
            "97\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 98 optimized output for Epoch 0:\n",
            "क ल ं ल र \n",
            "ग द ् ् ा र \n",
            "क ो ा ि _ ा ा \n",
            "क ो ा न \n",
            "क ा ल ी \n",
            "ग ल र न ी \n",
            "स ि द _ _ _ ा ा \n",
            "म ं ि ि ा ् ा \n",
            "ग ो ल ल \n",
            "क स ् र _ न ि _ ा _ ा \n",
            "क ि ि ं _ ा _ ल ी \n",
            "क ा ा न ी _ _ ा न स ् ट ि न \n",
            "म ल स ् ा \n",
            "क ि ा र ् म ा ा _ ् स ि स _ ल ि म ि _ _ \n",
            "क ् र ा ा स ि स \n",
            "क ि न _ _ ा र ी \n",
            "क व ल ा \n",
            "क र स ल \n",
            "ल ल ल ा \n",
            "ग ं ि ा _ ा र _ स _ र _ \n",
            "\n",
            "[STATUS] Batch 98/656 complete! Batch Loss: 0.32961854338645935\n",
            "0.94596773\n",
            "98\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 99 optimized output for Epoch 0:\n",
            "क र ् ा \n",
            "ग े ि ि न _ र _ न ी \n",
            "क ् ल े ि ि न \n",
            "म ि र ् _ ि ी _ र ि र ् _ ् स \n",
            "क ् ् ा _ ा ल \n",
            "क ल ा ल ा र ी _ _ ् स _ \n",
            "क ् ा ा \n",
            "क ि र ् _ _ म _ न ् _ _ न \n",
            "म ि ि म ा र \n",
            "ब ि ि ी _ _ _ न \n",
            "म ल ल ् ल \n",
            "स ् र ि ल म ल न \n",
            "म ं ि ि ा न ा \n",
            "म ि ल _ _ ् _ म ं _ ि ल _ म _ \n",
            "क ् र ् ् ि स _ _ _ _ _ ि स ् _ \n",
            "क र म ् ा ा \n",
            "क ो र ् _ _ _ स ् _ ि न \n",
            "म ा र ् ी \n",
            "क ल ि ि ा \n",
            "क ि र ा ् _ _ \n",
            "\n",
            "[STATUS] Batch 99/656 complete! Batch Loss: 0.33890271186828613\n",
            "0.9387097\n",
            "99\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 100 optimized output for Epoch 0:\n",
            "क ि ि ् स ी \n",
            "क र ् ् ् ा \n",
            "क क _ न ् _ _ _ _ ल ी \n",
            "क ि म न ि ल ् _ _ _ ं क _ _ _ _ _ स ् _ ् र _ ल ि _ ा \n",
            "क ा ल ् क \n",
            "स स म क ा ं \n",
            "क ि स ल म र \n",
            "म म ा \n",
            "क ग ् \n",
            "स द म ा \n",
            "क ा द ं ा र ी \n",
            "क ा द म ् ् र ी \n",
            "क म र ा ा ् र ी \n",
            "क ा ा ल ी \n",
            "क ् ् ् _ _ स _ स _ _ _ ् _ ् _ _ र \n",
            "क ि न _ _ ा _ स न \n",
            "स ा ि ी \n",
            "क क क _ _ _ र ी \n",
            "म ा र ् क _ _ _ ल र \n",
            "क ल े ं ् ् र \n",
            "\n",
            "[STATUS] Batch 100/656 complete! Batch Loss: 0.2958833575248718\n",
            "0.95080644\n",
            "100\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 101 optimized output for Epoch 0:\n",
            "क ो स ि \n",
            "क क ् ा ् _ _ ् म ् \n",
            "क क ् न \n",
            "क क ् ् ि ् \n",
            "ल ल ् ल ल \n",
            "क क ् \n",
            "क स र ् न \n",
            "क र ा ् ा \n",
            "क ल स ी र ी \n",
            "क म ि य ा \n",
            "क ् र ् ् \n",
            "क े न ी \n",
            "ब ् र ् क ि ं _ ् स _ ् _ स ् ल े _ ा न \n",
            "र ी ् ा _ _ _ र ् ट \n",
            "क ल ि य ि \n",
            "म े ल े न ा \n",
            "म ् ी ल ा \n",
            "क _ ् ् र ् _ ् स \n",
            "क ि क ि ् ि _ ा _ क _ र ् _ \n",
            "क े स ् ् र _ स ् _ ा _ ल _ _ ् र ी स \n",
            "\n",
            "[STATUS] Batch 101/656 complete! Batch Loss: 0.277751624584198\n",
            "0.95080644\n",
            "101\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 102 optimized output for Epoch 0:\n",
            "क ि ल ि य ा न \n",
            "स ् क ि र ् \n",
            "क ि ि ि ् स ् ट न \n",
            "ल ल ् ् ् ् \n",
            "ब म े _ ् र _ क ी _ ् ् ् \n",
            "क र म _ _ ् ् न ी \n",
            "क ् र _ ् _ _ स ि ् ि ल _ म े र ि ट \n",
            "स े म ् र \n",
            "म म न ि ् र ् स ि ट ी _ _ _ _ क _ ् े ् न ट ् र ी \n",
            "क न ी ल _ स ि म ् न \n",
            "क ु ल ा _ र ् स ् ् म \n",
            "क ा स ् म ा न \n",
            "स ् ि ् ल ् ट _ न ि ल स न \n",
            "ग स ि न ा \n",
            "ग ु र ् ् ् ् ा र ा _ क र ी र _ स ा ् ि ् \n",
            "ल ा र ् ् म ् न ् ट _ _ ् े न ् _ ् \n",
            "ग ी ् ा ं ् ल ि \n",
            "म म र ल ी \n",
            "क ा ् स े \n",
            "क ा ् ् \n",
            "\n",
            "[STATUS] Batch 102/656 complete! Batch Loss: 0.3508903682231903\n",
            "0.95080644\n",
            "102\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 103 optimized output for Epoch 0:\n",
            "ब म ि ि ल स र _ क न ् न म \n",
            "क ि य ् ् स र \n",
            "क म ि य ् ल ि ् \n",
            "क र ् ् \n",
            "क म ् ् \n",
            "क म ् ् ् र ा \n",
            "क म ा ् ् ल ् ल ा \n",
            "म म ् ा र \n",
            "क र ि ् न ा \n",
            "ब ल र ा म \n",
            "क ा र _ ् र ् े \n",
            "क ् र े ् र _ ल ा ् ल ि न \n",
            "ग म ि ा ् ् \n",
            "क म ् स ी _ क ् र ् ् ् \n",
            "क म ा ् ि ् ् ् ् े _ क ी _ _ ा ् ् \n",
            "क क स ि य ा \n",
            "क क ि म ि ल ी _ ् _ _ _ _ _ \n",
            "क ् ् ् ल \n",
            "ग न ् न ा न र म \n",
            "ब स ल ि ् ि य ा न \n",
            "\n",
            "[STATUS] Batch 103/656 complete! Batch Loss: 0.34330129623413086\n",
            "0.9314516\n",
            "103\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 104 optimized output for Epoch 0:\n",
            "म स ग ् ् ि \n",
            "क ल ् ् ् ् र ा \n",
            "क ् र े र \n",
            "क ा र ् क \n",
            "क ी म \n",
            "क स ल ि क ा \n",
            "क ग र ा म \n",
            "क े र ि क ा \n",
            "ब _ स ् ् य म _ ट ा _ म ् स \n",
            "क क स र ा _ ब स ् स ा _ _ स म \n",
            "क ग स ् र स \n",
            "ब न न न ी _ म ् \n",
            "ब म ग ा ल ी \n",
            "ब क ा ् ् र ् र \n",
            "क र _ ् र _ म ् ा \n",
            "स े र े ल ि य ा \n",
            "ब स ि ल ् र _ स र ् ल \n",
            "न ि ल य \n",
            "स ् ् ल न \n",
            "ब म स ी _ ल ् ा र र \n",
            "\n",
            "[STATUS] Batch 104/656 complete! Batch Loss: 0.2718820869922638\n",
            "0.95241934\n",
            "104\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 105 optimized output for Epoch 0:\n",
            "ब स ् र न _ य _ न ि न र ् स ि ट ी \n",
            "क द ा न ि \n",
            "क न ् न ा म म \n",
            "र व ि न न ् ् न \n",
            "ब स ि य न _ ् स ट ल ् स \n",
            "क ि म स न ी \n",
            "ब म न _ न स ी न ा \n",
            "स ु ल ् ् ा न ी \n",
            "न म ा _ न न र \n",
            "ग स \n",
            "ब ा न _ ् स _ स स _ स स ा \n",
            "स ् ् े क ् र ् र ा म ा \n",
            "क े न े न ी _ न ट ी न \n",
            "स ि न स ि न ा न ी \n",
            "ब क ि य _ न ल _ ् ी न \n",
            "ब ल व ी र \n",
            "ब म म ् ल \n",
            "ब ् र ी क ् \n",
            "ब व ि न ा न \n",
            "ब ा ल न न ् ् र \n",
            "\n",
            "[STATUS] Batch 105/656 complete! Batch Loss: 0.30955567955970764\n",
            "0.9548387\n",
            "105\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 106 optimized output for Epoch 0:\n",
            "क ो न ि म \n",
            "ब ि र ् ी \n",
            "स स न न न ् र \n",
            "ब स ् म ि य म \n",
            "ब े न न _ म न क क ् र \n",
            "क े े न \n",
            "म ु व ् ी \n",
            "ब ो र _ म ा न _ स स र \n",
            "ब स े े र े र े _ _ े ् ट _ स ् ट स र \n",
            "ब म ल े ा स \n",
            "ब म ा र ् य स स ा \n",
            "स स म ा न ् \n",
            "ब क न ् स _ ब ् ल ि क ् स \n",
            "ब क ् ् य \n",
            "ब म न ि य न _ _ ा _ _ \n",
            "ब े व ि न _ म न ल ् क म \n",
            "न य _ र ा स ् ् ा \n",
            "म े र ि े ल \n",
            "र ा न _ _ ् र ् ि स ् स ा \n",
            "ब ् र ि स र \n",
            "\n",
            "[STATUS] Batch 106/656 complete! Batch Loss: 0.30316904187202454\n",
            "0.9516129\n",
            "106\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 107 optimized output for Epoch 0:\n",
            "ब क ् ् _ क े _ _ ् _ स ा न े \n",
            "स म र े े न न \n",
            "ब ु े ब ा \n",
            "ब ु र ् ् ा _ _ र ा \n",
            "ब न ा न _ _ ा _ म _ स य _ न \n",
            "ल ा र स े न \n",
            "ब ा न े न ् _ _ _ _ ट र न े े न ल _ _ ् ल ा _ स ा \n",
            "ब े र ् े े ् स स े _ े न \n",
            "ब र _ क न न \n",
            "ब ि ल ा न न ी \n",
            "न ि य े ि \n",
            "ब ् ि ल ् ् े म _ ब _ _ _ म ् य _ _ ि य म \n",
            "ब े ि _ व ि _ ि ् ् ट _ स े व ा _ म े _ ल \n",
            "क ो स म ् ब ट _ र _ _ स क ् ् न \n",
            "ब य _ न म ् र े _ म ा _ \n",
            "ब ा ब े र \n",
            "क ् र े स े े ट _ स ि ट ी \n",
            "ब स र स ् _ र \n",
            "ब व ा न \n",
            "ब क _ न ा न _ क ि न ा र े _ _ स \n",
            "\n",
            "[STATUS] Batch 107/656 complete! Batch Loss: 0.38882115483283997\n",
            "0.9379032\n",
            "107\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 108 optimized output for Epoch 0:\n",
            "ब ि ि े ा म न ी _ स _ र ् ा स \n",
            "ब ा न ् ् व ी \n",
            "म ु े े _ े क ् े ि _ _ ो \n",
            "ब े ु \n",
            "र ि क े े व ि क \n",
            "ब े े ् र ि क _ _ स ् र े े \n",
            "अ ल न ि य ा \n",
            "क ु द \n",
            "म ा ल ् व ि न ा \n",
            "ब र म े े े \n",
            "ग ् र े े ा \n",
            "म े े ल _ _ _ _ _ _ क ो व \n",
            "ब ् र ी व े ् स \n",
            "ब ग ी \n",
            "ब ल ा म े \n",
            "ब ् ल े े े य \n",
            "ब _ ब ् र ि ट ि _ _ म ् य _ _ ि य म \n",
            "म ा स े म \n",
            "ब ा ब ् ल ो न ो न \n",
            "ब ब ि न ो ल े क ् स _ _ _ _ स ् ट ् र ी _ स \n",
            "\n",
            "[STATUS] Batch 108/656 complete! Batch Loss: 0.31449949741363525\n",
            "0.95564514\n",
            "108\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 109 optimized output for Epoch 0:\n",
            "ब स ् े क \n",
            "ब े े र े म _ स ् ट ो र ी \n",
            "ब े े र _ े ल न _ _ ो य \n",
            "ब ि े \n",
            "ब ि ल ि स \n",
            "ब ो र ् ट _ _ ् र े _ र ि क \n",
            "ब े ि य ा ल ा \n",
            "ब ब ् ् ु ल _ _ व ् व ा _ \n",
            "म न _ क ा _ म ी \n",
            "ब ि न ो े \n",
            "ग ु ल न ा र \n",
            "म म ा द े े \n",
            "ब म े ल ी \n",
            "ब स म ा न _ म ल \n",
            "ग ु े े े ी \n",
            "ग ु े र ा े _ स ् ट े ट _ _ े ट ् र ो \n",
            "ब े न ि य स \n",
            "ब ो र ् ट _ _ े ल ा व े य र \n",
            "ब र ् े ा _ ल \n",
            "ब य न ा र ा य \n",
            "\n",
            "[STATUS] Batch 109/656 complete! Batch Loss: 0.2609812319278717\n",
            "0.9645161\n",
            "109\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 110 optimized output for Epoch 0:\n",
            "ब म ा र ी _ _ ा न \n",
            "ब े र ् म ि य म \n",
            "ब ु ् ा र _ _ म र ा न \n",
            "अ न ा क ा ल ल ् ल े \n",
            "ब ि ल _ क ा र ् ल स न \n",
            "व ि ल ् ल ा व \n",
            "न ब ि े \n",
            "म म े े \n",
            "ब र े ी _ क े _ ल ा ल \n",
            "ग ि ल ् ल े स \n",
            "अ ु ल स ा \n",
            "ब े र _ _ _ _ _ _ _ ् र ी ि य स _ क ् र ा न \n",
            "द ो े ा र ा \n",
            "प े े ी \n",
            "ग र म _ म स ा ल ा \n",
            "ग ् य े ा न \n",
            "क ह ा ा _ _ _ _ म म े ि ल _ े े र ी \n",
            "ब ल ा ा \n",
            "क ् र ि स _ _ े ल \n",
            "ब े क ो स ् ल ो ा ा \n",
            "\n",
            "[STATUS] Batch 110/656 complete! Batch Loss: 0.26122432947158813\n",
            "0.96693546\n",
            "110\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 111 optimized output for Epoch 0:\n",
            "ह े र े े े \n",
            "म ा द ् र े \n",
            "स ् त व ि े ा \n",
            "ह म ा र ा _ \n",
            "ल ल म े र \n",
            "ह म _ म ी व ा न \n",
            "ग म े र _ म _ े ल ट ि स ् ट \n",
            "व ि न े ी \n",
            "व ि ि ा ल ा ् ी \n",
            "अ म र ल \n",
            "अ र म ल ु र ी \n",
            "ह ा स ् न ा \n",
            "ब े न े े ी \n",
            "स ा न ा \n",
            "ब ी व ि ि _ ी _ _ म ् ल े न ि ट ् र े ल \n",
            "म ु ल ् क र ा _ न \n",
            "म म ् म म _ े े ् _ _ क े ् म ी र \n",
            "अ े य ा \n",
            "म य ् य े ा \n",
            "स ् ट े े ी \n",
            "\n",
            "[STATUS] Batch 111/656 complete! Batch Loss: 0.2603033781051636\n",
            "0.96048385\n",
            "111\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 112 optimized output for Epoch 0:\n",
            "प र ा े _ े स _ म े े \n",
            "म ि ि ल ी ल ि न ् स \n",
            "म ु म ् त ी \n",
            "म ो र ् ट _ ट ् र े े न ् ट ल \n",
            "म र े \n",
            "म ल स ् ट ् र ी स \n",
            "अ े े र \n",
            "म ि ल े ट _ _ म _ ि य ा \n",
            "म म द ् र क ि े ो र \n",
            "म ा ा _ क ी _ स \n",
            "क त र \n",
            "प ् य ा र े म न \n",
            "ह ल द ी \n",
            "र ा ल म _ _ _ ा म स \n",
            "ग ो व ि ि ् ी _ म ा र ा \n",
            "स ा ा े \n",
            "व ा य र ल े स _ म ् य े ि य म \n",
            "म ा त म _ े म म ि \n",
            "अ क द म त \n",
            "स े व ा र ा म \n",
            "\n",
            "[STATUS] Batch 112/656 complete! Batch Loss: 0.2862588167190552\n",
            "0.96048385\n",
            "112\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 113 optimized output for Epoch 0:\n",
            "प ् र म म ा \n",
            "म े व ि _ _ म _ व र \n",
            "न े र ि न ा \n",
            "ग ो े े ् र े \n",
            "स ो ् ि न ा \n",
            "म े म े ल ल क र \n",
            "म न े ल ा \n",
            "म म ा म _ र ा _ ा \n",
            "म ल र ी _ क ो ल _ व ् ् ि ट े क र \n",
            "ब ् य ा व र \n",
            "म ो र ् ट _ म ल न ो े ल \n",
            "म ु ् ल र \n",
            "म ल े \n",
            "म ल ा ा ् य े \n",
            "म ् र म ् ल _ व र ् ल ् _ _ ट _ व र \n",
            "म न म े े य \n",
            "ब ा र ् क न _ _ ो र ् ट \n",
            "व ा ट र _ प ो ल ो \n",
            "म ि म े न _ म ा र \n",
            "र ा म ा ा \n",
            "\n",
            "[STATUS] Batch 113/656 complete! Batch Loss: 0.24073752760887146\n",
            "0.966129\n",
            "113\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 114 optimized output for Epoch 0:\n",
            "क ी र ् ् ि _ _ ट ा म \n",
            "स म ल म र ् ट _ स म े ो ् ी _ म ा म _ क ी _ म ् ि म ा \n",
            "र ् क ी \n",
            "ब ा ल ा \n",
            "अ म े स र \n",
            "र ् र र ् ट _ ट ट क ि न ् स \n",
            "क ल ल ी \n",
            "प ् र ् ल ल ् ल ि े \n",
            "म म क क ् व े र ी _ य म न ि व र ् स ि ट ी \n",
            "म े म ु स े ल ा _ म ा म स _ प ् र ा ट ट \n",
            "ब न ् ् ु ल ा _ व र ् न ा ल ट र ा \n",
            "म म े न ल े स ् ट \n",
            "म ह ी ् ु र _ र ् म ा न \n",
            "म न म _ म न म \n",
            "म र ् र ा ् ि म _ न ि य ा स \n",
            "म म ा र ् य _ म ट ल स ी \n",
            "म ो ् ् र ा _ म ो ् र \n",
            "प ् र ि ं स े स \n",
            "म म ा व त \n",
            "म ा म _ क ा _ _ ट ल \n",
            "\n",
            "[STATUS] Batch 114/656 complete! Batch Loss: 0.3223336637020111\n",
            "0.9548387\n",
            "114\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 115 optimized output for Epoch 0:\n",
            "म ह ा व ी र \n",
            "म त ् स ा ह \n",
            "म म ि क े \n",
            "क ा र ् स न \n",
            "म ो े \n",
            "म ु ल र ी \n",
            "म ु ल ् र ी \n",
            "म प ु ल _ _ र ् ट ा \n",
            "म म म र \n",
            "क ा ह ल ो \n",
            "म म ि ि ल \n",
            "म म म ा र ् र ा \n",
            "म म न _ ट ट ् _ _ म ी व \n",
            "अ ् ो क _ न _ र \n",
            "म ु स ा व ल _ ट ं क ् ट न \n",
            "म र ् न _ ट र ् ी \n",
            "स ो न ा ट ा \n",
            "म ो र ् ट _ स े ं ट _ ट न ी \n",
            "र ो े _ क ल न े ड ी \n",
            "ब ी क ा न े र _ _ ो र ् ट \n",
            "\n",
            "[STATUS] Batch 115/656 complete! Batch Loss: 0.24121083319187164\n",
            "0.966129\n",
            "115\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 116 optimized output for Epoch 0:\n",
            "म म म त \n",
            "म ि ट न े स \n",
            "प ् र म ि े ि \n",
            "म े ं म \n",
            "ह ं प ा क \n",
            "ह म न _ क ी _ ट क ् क र \n",
            "म े र े स ा \n",
            "न र ् स ि ं ट \n",
            "व ड व े क र \n",
            "ल ल र े ं स _ ट ल ी व र \n",
            "ल ा म ा \n",
            "ब द न ा प ी र \n",
            "ह स ा क ा _ व र ् ल ् ड _ ट ् र े ड _ स े न ् ट र \n",
            "प म म ी \n",
            "स ु म े य ् य ा ह \n",
            "क ् र ् र े क \n",
            "र ह ी ल ा \n",
            "म े े \n",
            "क ो ल ् र न \n",
            "म म म त क ल ा \n",
            "\n",
            "[STATUS] Batch 116/656 complete! Batch Loss: 0.19964542984962463\n",
            "0.9806452\n",
            "116\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 117 optimized output for Epoch 0:\n",
            "ह ा म ि म \n",
            "ग ो ह ा न ा \n",
            "म ् य ा म ल \n",
            "ल ल े ो ी ा र ् म \n",
            "म ु त ा स ि म \n",
            "स म स ् य ा \n",
            "ह र ा न _ क ी _ ट क _ र ा \n",
            "ह ् ी \n",
            "म म क ल ि न \n",
            "स ् न ो व ी \n",
            "म ड ी क र \n",
            "म ि त ् त म र \n",
            "न े र ् ट _ म ् र ी म ् म न \n",
            "म स ् न ी म \n",
            "र ो म ि य ो _ ट ट ल ि य ट \n",
            "म र ा \n",
            "ल ो क ल ा ल \n",
            "म म ल \n",
            "म ा म ं ट _ र ि व े ल स ् ट ो क \n",
            "ह ड ो ल ी \n",
            "\n",
            "[STATUS] Batch 117/656 complete! Batch Loss: 0.1983916461467743\n",
            "0.9766129\n",
            "117\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 118 optimized output for Epoch 0:\n",
            "ब ा ल ी ो ल ा ल \n",
            "म ् र ी ी ् म \n",
            "म ा म ं ट _ क ा र म े ल _ स ् क क ल \n",
            "म न ि त ा \n",
            "व े त ा ल \n",
            "क े स ा व ा \n",
            "म म ा _ क ि न _ क स ी _ र ा \n",
            "म े ल ् ी ि न ा \n",
            "क व ी ी ् व र \n",
            "म ा र ् क ी \n",
            "ल ा म ु क न ् स _ ड ी _ क स े म ् ट ो ल ा \n",
            "म क म ि न ि क _ क क र ् क \n",
            "म म ल े ल _ क े _ क ट ट र ी _ क ो र ् ट \n",
            "म े व ा \n",
            "म ो र ् ट _ र े य ल \n",
            "म ी त _ क म ा र ी \n",
            "न व र े \n",
            "म म म ी \n",
            "म म म म \n",
            "म ् र े ं क ो ी स \n",
            "\n",
            "[STATUS] Batch 118/656 complete! Batch Loss: 0.24701757729053497\n",
            "0.9629032\n",
            "118\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 119 optimized output for Epoch 0:\n",
            "म ो र ् ट _ क ा र ् ट र ा क ट \n",
            "प ् र स ा \n",
            "ब ी \n",
            "म क ् त ा \n",
            "ल े स ा \n",
            "म ं ् ् र ा ी \n",
            "स त ् य म म र ् ि \n",
            "प ् र े म ि य ो _ क क न क र े ल ा \n",
            "ब ं े ु \n",
            "म े े ा \n",
            "प ् र ी स ् ट ल े _ म े ड ल \n",
            "ब ि ् ी ल ी र \n",
            "ब ा क ा र \n",
            "म त ् स ा \n",
            "म ो ड ा _ क क े \n",
            "न न ी ी \n",
            "म र ा र _ क क क ी \n",
            "क क ि प ् र ी \n",
            "म म ा र \n",
            "म स न ा \n",
            "\n",
            "[STATUS] Batch 119/656 complete! Batch Loss: 0.20691706240177155\n",
            "0.96854836\n",
            "119\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 120 optimized output for Epoch 0:\n",
            "ब ल र ा म _ क ् र ी ् \n",
            "ब ि क ् र म \n",
            "ग ो ो र ा _ क ं क ् ट न \n",
            "ग ो े ल े \n",
            "ग ु र े ी \n",
            "प ु र ा न ा _ म ं क ि र \n",
            "न ो र े क स ल ् क \n",
            "म म ् य म क \n",
            "ह ि त े े _ म ो ी \n",
            "ज ु े र ी \n",
            "स ा र ा \n",
            "र े े ा \n",
            "ल ं ड न _ म क ट ् र ो क स ल ि ट न _ क क न ि व र ् स ि ट ी \n",
            "म न ि र ् व ा \n",
            "ब ् र े ं ड न _ क ् र े स व े ल \n",
            "स ् ट े न ल े _ ड े _ स ि ल ् व ा \n",
            "क ल ् ल ा क न _ स ् क ी ी ं क _ व र ् ल ् ड _ क क \n",
            "ब ् र े न ् स ् व े े \n",
            "क े न ि क ा \n",
            "स ि ् ् स ि _ व ि न ा य क \n",
            "\n",
            "[STATUS] Batch 120/656 complete! Batch Loss: 0.28667235374450684\n",
            "0.9629032\n",
            "120\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 121 optimized output for Epoch 0:\n",
            "म स ी न ा \n",
            "र ा य न े \n",
            "र ी _ क े ् र ो \n",
            "क ि र ा \n",
            "ज े े र ् स ् स \n",
            "म ग ल े \n",
            "क े ं े _ ल ा ं ल \n",
            "म ु ड े ा \n",
            "म ु ड ा \n",
            "क ल स ा ं क ् र ा \n",
            "स ी र ा \n",
            "म ि ल न _ स म ा र ा व ी र ा \n",
            "प े ड ् र ो \n",
            "म े ा न ी \n",
            "अ े ि क ा र \n",
            "फ ु े र ् क ा न \n",
            "अ े ि त ा \n",
            "न स ी र \n",
            "ग ु ल ् ल ल ल र \n",
            "फ ल े ल _ क े ा र \n",
            "\n",
            "[STATUS] Batch 121/656 complete! Batch Loss: 0.171526700258255\n",
            "0.9774194\n",
            "121\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 122 optimized output for Epoch 0:\n",
            "ब ् र ि स ् ट ल _ क ल न ल _ क ो र ् ट \n",
            "ब ं स ा _ _ म ल ं _ क र े क ल ा \n",
            "म ि त ि \n",
            "ब ि त ् स र _ र ि क र व ा य र ् \n",
            "अ े ि व र \n",
            "ह ा व े ा _ क क ् स ल ् र े स \n",
            "स ु े ा न ं \n",
            "स ् व े े ा \n",
            "म ल द ा \n",
            "ह ् य े स ् ट व ि ल े _ क ् र ि क ् क ि य न \n",
            "स म ि ल ी _ प ो स ् ट \n",
            "स ड स क _ क ा ल \n",
            "ह म ा र ी _ क ि स ् म \n",
            "ग स व क ् र \n",
            "स ं ं े र ा \n",
            "र ा त \n",
            "ब ा ल _ क े ट ी \n",
            "अ ब ् ् ु ल _ क ् ी \n",
            "स स ि ् ् स ु \n",
            "क ् र े े ् स _ क ा य ो क े म \n",
            "\n",
            "[STATUS] Batch 122/656 complete! Batch Loss: 0.2779933214187622\n",
            "0.96209675\n",
            "122\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 123 optimized output for Epoch 0:\n",
            "ब ि र ् ी \n",
            "अ न ु र ा _ र ा ा स ि ं स े \n",
            "स व ् य स ा ी \n",
            "ह ं स \n",
            "फ स े े ल ा \n",
            "म ि ल _ म े द स र \n",
            "ब े न ् न े न \n",
            "क ल र ो ल ि न \n",
            "स य ् य द _ क स ि ् _ क ल ी \n",
            "ग स \n",
            "ब ा ल म ि \n",
            "ब ो र ् ट _ स स ी न ि स ो स न \n",
            "ब ल ् ट न _ क ि ि म स ु र ा \n",
            "द ु र ् ल ा _ म ा ा \n",
            "म म स ा \n",
            "ब ् र े य ा \n",
            "ग ् र ् \n",
            "म ो ग े \n",
            "म ं स ल र ा \n",
            "ब ि ल _ क ी _ र ा न ी \n",
            "\n",
            "[STATUS] Batch 123/656 complete! Batch Loss: 0.20276625454425812\n",
            "0.9701613\n",
            "123\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 124 optimized output for Epoch 0:\n",
            "फ ी र ो ा \n",
            "अ ल ् ल े ल ी \n",
            "अ ् े े ा \n",
            "स े म _ ग ् र ु ल \n",
            "ब ो र _ क े _ क र _ क ो र न ी \n",
            "ब ी ल ् ड ् स स _ म े ड ल \n",
            "फ ि ल \n",
            "ल ् य ल स ी \n",
            "प ु ल ि स _ स ् ट े स न \n",
            "प ं ् ु ल ा \n",
            "ल क ् ् द ् व ी ल \n",
            "ब र _ म े ं _ र ा म _ म ल ी _ म े ं _ स ् य ा म \n",
            "स े व न _ म ा म ल ् स \n",
            "म ् ा ु \n",
            "ज े स ी _ स ल क ् स न \n",
            "म ु े ि े स ् स स र ल ु र \n",
            "ब म न ि व र ् स ि ट ी _ _ स _ _ ं ड ी \n",
            "ब ा र े \n",
            "क ि ं ब र \n",
            "म े ल ि य ा \n",
            "\n",
            "[STATUS] Batch 124/656 complete! Batch Loss: 0.2483329474925995\n",
            "0.96693546\n",
            "124\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 125 optimized output for Epoch 0:\n",
            "ज य स ु स ा \n",
            "ब ल े र ा स \n",
            "ल े ल े \n",
            "र े स \n",
            "अ ल ् स ो ं स े \n",
            "ब ि र ं त न \n",
            "ब ् ा द ु र \n",
            "क ल ल ी \n",
            "स न ् व र _ स ु स ल न \n",
            "क ् व े े े ल \n",
            "न न व न \n",
            "ब ल ् ड ो र े ो \n",
            "न ज ल ा \n",
            "ग ि ि ा र न \n",
            "ग ो ल ् ड स ् म ि ल _ ब ु क _ प ् र ा स े \n",
            "अ े ि म ा न \n",
            "अ न ल ा \n",
            "ब े र ा ज स न ो _ न े र ो \n",
            "क ् र े ग _ व ि ि ा र ् ट \n",
            "ब न ् द ु व \n",
            "\n",
            "[STATUS] Batch 125/656 complete! Batch Loss: 0.20678354799747467\n",
            "0.9741936\n",
            "125\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 126 optimized output for Epoch 0:\n",
            "स े ं ट _ म ा _ क ल ् स _ स क े _ म ी _ े न ् न \n",
            "र ा म _ म व ा र \n",
            "अ ब ् द ु ल _ म ल ी ल \n",
            "क ल ा \n",
            "ब ल र ा \n",
            "ब ा र ा \n",
            "ग ं ग ा ल ु र _ _ ल म \n",
            "फ स व \n",
            "म म ग न य न ी \n",
            "म ु ् ् त ा क _ म ् म \n",
            "ब ि ं स ् ट न _ ब े ं स ा म ि न \n",
            "ल ल ं ग ल ी \n",
            "ब ज _ क ा _ म ् _ म र \n",
            "ब ो ग र ा ज _ स ि ं स \n",
            "प ा ल क \n",
            "ब व ा र ा _ ब ा ल \n",
            "ज स ा द र ा \n",
            "ब ु स ् म ि ल \n",
            "प े ं ट ा स स स स ् ट \n",
            "ब ि न ल ल ं _ ि य ा _ प ् र ा _ _ _ _ स र _ ल ि ट ् र े र \n",
            "\n",
            "[STATUS] Batch 126/656 complete! Batch Loss: 0.27150508761405945\n",
            "0.9596774\n",
            "126\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 127 optimized output for Epoch 0:\n",
            "स क ् व ल ड ् म स \n",
            "ब व र ् ट न _ म ल ट ि स \n",
            "ब ि प ट ् र ी _ म व ा र ् _ \n",
            "ब े ल म ल ा ल ी \n",
            "अ ब ् द ु ल _ व क ी ल \n",
            "ब ं ड ल ब ा म \n",
            "म ल ग ो म ि न \n",
            "ल ि ं ग न म क ् क ी _ _ ल म \n",
            "क ा म य ा \n",
            "ब प र म ु ु _ ज ं क ् ् न \n",
            "ब ी ल ् त ि म ा न \n",
            "फ ो र ् ट _ न े ल ् स न \n",
            "प ा म र _ ट न _ ् र ा _ स े ट \n",
            "म ु क ु ट ु र \n",
            "म ु र े ग न \n",
            "म ु ि क ा \n",
            "न ि र े ल म ा \n",
            "र ा म े ं द ् र \n",
            "म ु ि ल ा ल \n",
            "ब र ी \n",
            "\n",
            "[STATUS] Batch 127/656 complete! Batch Loss: 0.20696896314620972\n",
            "0.975\n",
            "127\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 128 optimized output for Epoch 0:\n",
            "न ज ् म े द ् द ी न _ र ा म ी \n",
            "ब ो र ् ट _ ब ि ज _ व े क ट न \n",
            "अ व े ल ि य ा \n",
            "फ ो र ् ट _ म _ ल ् ट ् र ी \n",
            "अ य ् य प ् प न \n",
            "ब ु स ल न \n",
            "ब ी म ा म ं क र \n",
            "ब े स _ प र ् े स \n",
            "ग ो व ि ं द र ा ज ् ज ा _ प े र _ म ा ल \n",
            "अ ज ं त ी \n",
            "ज ज र ् ज _ प ल क \n",
            "ग व े म ा ल \n",
            "ब ् र ा ज ि व ि ल े \n",
            "स ी व ा न \n",
            "ग ा य े े न ा \n",
            "ब े ो ु \n",
            "ब ु र ा \n",
            "ज ु ु ल ् म _ क ा _ ब द ल ा \n",
            "ग ो र े स ु व र \n",
            "म ल ा म _ म ल र \n",
            "\n",
            "[STATUS] Batch 128/656 complete! Batch Loss: 0.2027023881673813\n",
            "0.9806452\n",
            "128\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 129 optimized output for Epoch 0:\n",
            "ग ो ग ि न ी \n",
            "ब ा ल म े र _ ल _ र ी \n",
            "ल े स ् ल ी \n",
            "ब ु ा ं क \n",
            "अ े व ा \n",
            "व र ् ल ् _ _ म ल ं प ि य न _ ि प _ म न _ ब ल _ ल न \n",
            "ब ल े े ् व र ी \n",
            "ब ु न ा म \n",
            "अ ल ी ग ं ज \n",
            "ब ि प र _ ग ो र \n",
            "अ ु ा ब \n",
            "क ो य न ा _ _ ै म \n",
            "ब ् र ा य ल ा _ म र स ी \n",
            "स ि व न ी \n",
            "प ् र े म _ न ग र \n",
            "अ व ा न ि य ा \n",
            "प ज ज ा _ क े _ _ म ल \n",
            "स ् क ा म ट _ क ै ं प \n",
            "ब े न _ व ा र ् न \n",
            "क ै ड ब र ी \n",
            "\n",
            "[STATUS] Batch 129/656 complete! Batch Loss: 0.19834446907043457\n",
            "0.9741936\n",
            "129\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 130 optimized output for Epoch 0:\n",
            "प ल ् ल व \n",
            "फ ो र ् ट _ ब ै ट ल _ ो र ् ड \n",
            "ग ु र ा र ु \n",
            "न क ल ी _ क ी र ा \n",
            "म ु र ् र े _ प ा र ् क र \n",
            "ल ु ल \n",
            "स ि म ् ड \n",
            "स ग ा म ी \n",
            "ज ट ा _ प ं क र ी \n",
            "अ ् र े ड ा \n",
            "स ा ग र _ क ी _ क न ् य ा \n",
            "ब ् र ी व ल ् ल \n",
            "फ ज ो र ि ं ट \n",
            "म ा ल ् क म \n",
            "म म ल क े ल ् म \n",
            "अ ा र ् ट म म र \n",
            "ल ि व न े ल \n",
            "ब ा ं क र \n",
            "ह ल ु ल \n",
            "ब न ि व ा न े _ ब ा ज ी \n",
            "\n",
            "[STATUS] Batch 130/656 complete! Batch Loss: 0.1633930206298828\n",
            "0.98306453\n",
            "130\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 131 optimized output for Epoch 0:\n",
            "ज े ट _ क य र व े ज ट \n",
            "र ा म ा न ु ज न _ प ् र ा ट ट \n",
            "स ि ल ् व र \n",
            "क ा र म े ल _ क _ न ् ट व े ं ट _ स ् क _ ल ल _ क ा क ् य _ प ु र ी \n",
            "ब स ी _ क ा _ न ा म _ म ु न ि य ा _ क ै \n",
            "क ी र ् क ि क ु म ा र \n",
            "व ि ट ् ट े ल \n",
            "र ा ज _ ल क ् ट ् म ी \n",
            "ब _ प म े र ि क न _ क र ् _ क _ _ क ो ल ी _ म ा र ् ट य र ् स \n",
            "अ न ् न ी ग े र ी \n",
            "स ै प _ प ं ड ि य ा \n",
            "ग ज ् व \n",
            "ग ो ग ि य ा \n",
            "ब क ी ी ा \n",
            "ब ग ् र ी क ल ् ट र ल _ ब ै ं क _ क _ _ क ा _ न ा \n",
            "ब व र े ट \n",
            "फ ा व क \n",
            "म े न \n",
            "ब े ग े म \n",
            "म ु र ि ल ि व \n",
            "\n",
            "[STATUS] Batch 131/656 complete! Batch Loss: 0.2746120095252991\n",
            "0.96693546\n",
            "131\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 132 optimized output for Epoch 0:\n",
            "म ै न ा \n",
            "फ ो र ् ट _ ज ट क र ी _ ट े ल र \n",
            "अ न ु े ् े म \n",
            "प ् य ा र _ क ी _ प ् य ा स \n",
            "अ म र र ा ज \n",
            "क ् र े ग _ क ् य ु म ि ं ग \n",
            "व स ् न ा \n",
            "ल े ग _ क व ा र ् ड ् ट स \n",
            "ब ् र े क क न _ ब ि क क न ् स \n",
            "फ ो र ् ट _ ब ् र े ग \n",
            "प ् य ा स ा _ स ा व न \n",
            "क ् व े न स ा ं ग \n",
            "ब न म ा न ु \n",
            "क स म े ं _ व ा द े \n",
            "ब क _ क ा _ ल क क ा \n",
            "ब ज ड े म ि क ् स ु _ क ो स ा न \n",
            "अ म ा ं ड ा \n",
            "म े म \n",
            "र ा प ् े ी \n",
            "अ ी प _ क ा स ग ु प ् क ा \n",
            "\n",
            "[STATUS] Batch 132/656 complete! Batch Loss: 0.2008884847164154\n",
            "0.98145163\n",
            "132\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 133 optimized output for Epoch 0:\n",
            "व े ल ि न \n",
            "अ े ल ि े \n",
            "क े व ि न _ ड ु क र ् स \n",
            "ब ् र े म _ ब ा ल \n",
            "अ ि क ् र र \n",
            "म ा क _ क ी _ म म ा \n",
            "ज व द ा न \n",
            "व े ल ि य ं ट \n",
            "अ ं ब ु र ा ज \n",
            "क म ा ल ि \n",
            "म ा ल ा य ल ा _ म न ो र म ा \n",
            "अ ् र ि न ि ट ी _ ब ा य ो ट े क \n",
            "स ा व न ा \n",
            "स ा क _ स व ा ल \n",
            "क क ् ज क ो _ न ो ब ल \n",
            "अ म र ी क \n",
            "र स र ा ज \n",
            "ल े स ि य ा \n",
            "न ग ि न ा \n",
            "न ग ी न ा \n",
            "\n",
            "[STATUS] Batch 133/656 complete! Batch Loss: 0.13239334523677826\n",
            "0.98790324\n",
            "133\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 134 optimized output for Epoch 0:\n",
            "क े न ् य क न \n",
            "अ द ् य व \n",
            "अ क र ी न ् स \n",
            "प ् ल े ट ो \n",
            "म ै क ् र ा व र ु ि \n",
            "क े व ग ा क व क र \n",
            "व ि ज य ा \n",
            "ब र ् ल ि न \n",
            "य े न ि व र ् स ि ट ी _ क क _ क _ स न क ा क न _ क ो स ् ट \n",
            "क ् य क ल े ट क प क क र ् ड \n",
            "न े ा ल ी _ क ो ल \n",
            "क म म ा क \n",
            "ज े ि न _ प ा र ं क प े \n",
            "क ् य ा म _ क ी _ क ो ग न \n",
            "अ म े र ि क न _ क क ् स प ् र े स \n",
            "क ि र ा ग क \n",
            "ग ् ल ो म र _ क क ् स प ् ल ो र र \n",
            "ल ो ल ा _ क व ा र ् ड ् ट स \n",
            "म ि स _ क ् र ं ट ि य र _ म े ल \n",
            "र ा क व \n",
            "\n",
            "[STATUS] Batch 134/656 complete! Batch Loss: 0.21065671741962433\n",
            "0.9733871\n",
            "134\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 135 optimized output for Epoch 0:\n",
            "अ ब ् व ु ल _ म ु ग क ा न ी \n",
            "क ि क र ु र ा म \n",
            "ज ो स े ल ि न \n",
            "व ि य े न ा म \n",
            "र े न _ क क ल ् स ि ं क ं ग \n",
            "अ ा क स े न क क प \n",
            "न ा ग _ म ि \n",
            "प ् य ा र _ म ो क क ् ब \n",
            "ज ि म ी _ म े क र \n",
            "र ु प ा क ा \n",
            "र स े ल \n",
            "र े स े ल \n",
            "क ् र ी न ि ट ी _ ल ु क र े न \n",
            "व र ् न े क \n",
            "स ् व र े प \n",
            "ब ा ग ब क र ा \n",
            "अ ि प ् स े \n",
            "स ज ् ज ो _ र ा न ी \n",
            "म े ल ् व ि न \n",
            "स ो ल न \n",
            "\n",
            "[STATUS] Batch 135/656 complete! Batch Loss: 0.14929403364658356\n",
            "0.9822581\n",
            "135\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 136 optimized output for Epoch 0:\n",
            "ग ् र ो स ् ज ी \n",
            "अ े ी म ु ल _ क न ि क \n",
            "म ु क ् ल \n",
            "ज े े न ो क ो न \n",
            "क ा क व े _ क ो ल ् ड ि ं ग ् स \n",
            "क ा र ि क क ा \n",
            "म ा य व \n",
            "ज े ी _ ट े ल ी ि ल ् म ् स \n",
            "स र ा द ि ं क क _ म ु क र ् ट ी \n",
            "स ल े क ् ट ् र ो ल क ् स \n",
            "क ं ड ु ज ा \n",
            "म म ि क ा \n",
            "न े त न \n",
            "न े ट ि ं ग क क म _ क स ् ट _ म ि ड ल ल ं ड ् ट स \n",
            "अ ट र े \n",
            "अ र क ा न \n",
            "स ग _ क क ल क ं ड _ क ी प \n",
            "ल े ट ी ि य ा \n",
            "य ु क ा न ् न ि स \n",
            "ज ा ं द ा \n",
            "\n",
            "[STATUS] Batch 136/656 complete! Batch Loss: 0.2182123064994812\n",
            "0.96935487\n",
            "136\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 137 optimized output for Epoch 0:\n",
            "अ प न े _ क प न े \n",
            "र ा ज _ न ं क ि न ी \n",
            "म ल े ा न ा \n",
            "य े र े न ि य म \n",
            "अ ा न _ ब क ा ु र \n",
            "ब र न ल ा \n",
            "ब र न ा ल ा \n",
            "अ ब ् ब ी र _ क क म \n",
            "ल ो क े े \n",
            "न े न ा \n",
            "ज े र ् ज ि य ा _ प े स ि क क \n",
            "अ ि न \n",
            "अ क ् य त ा \n",
            "स ि ल ् व र ल ा क न _ स ् क क ल क _ ग ा ज स ि य ा ब ा \n",
            "अ क ी ल _ क ा न \n",
            "अ े र ा क \n",
            "अ े ि ज ी त _ क ा ल े \n",
            "ग े ा ल ी \n",
            "क ल न क क क \n",
            "क ् ल ो व ि स \n",
            "\n",
            "[STATUS] Batch 137/656 complete! Batch Loss: 0.17093461751937866\n",
            "0.9741936\n",
            "137\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 138 optimized output for Epoch 0:\n",
            "ज ो स न _ ब े ज स \n",
            "व ि क _ प ो ल ा र ् ड \n",
            "क ं स ् ट ी ट ् य क क न \n",
            "स ो स ल े \n",
            "म म न स ि ल ् व र \n",
            "म ग ् द ल ा \n",
            "अ ि ल ा य \n",
            "क ा र ् न े ग _ म े ड ल \n",
            "स ो म क ा ं त ा \n",
            "अ ् र े ं क ल ि न _ ड ी _ र े स ब े ल ् ट \n",
            "अ म े त ा \n",
            "अ े ल प ु र \n",
            "अ र े ल ि य ा \n",
            "अ ड व ा ल \n",
            "अ ो ल ो ं _ क ी _ स े ज \n",
            "क ो न ल ल न \n",
            "प ् र ु ड े ं स \n",
            "ल क ् य ् म ी ग ो प ा ल \n",
            "अ ं द ् र े ा न \n",
            "व ा र स ो \n",
            "\n",
            "[STATUS] Batch 138/656 complete! Batch Loss: 0.1679852455854416\n",
            "0.9822581\n",
            "138\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 139 optimized output for Epoch 0:\n",
            "अ र ् य े ं ् व र \n",
            "म ल ं ड ी \n",
            "ह ु ो _ स व े र ा \n",
            "ब र ् ड े स \n",
            "म ा ं ड म \n",
            "र ं ज ी ो _ म द ु र ा स ि ं े \n",
            "प ् र े ा स \n",
            "स ि र ् ग ो न ी _ व ि व र \n",
            "व ि ं ् व ा स \n",
            "स ो _ क ी _ क ो \n",
            "स र ड _ क ो र ् ट \n",
            "स ल न ् ट ा _ म ो न ि क ा \n",
            "अ ो ा र ् य स ु ा \n",
            "ज ा य ड े न \n",
            "म ि र ् र ा \n",
            "ग ु ं ड प ् प ा _ व ि ं ् व न ा ल \n",
            "र म ा न ी \n",
            "ब ं क ि म \n",
            "ग ो प ी ं द _ ज ा स स स \n",
            "अ ब ् द ु ल _ न ो ी \n",
            "\n",
            "[STATUS] Batch 139/656 complete! Batch Loss: 0.16965444386005402\n",
            "0.9798387\n",
            "139\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 140 optimized output for Epoch 0:\n",
            "अ न प ट ि य ा \n",
            "अ े ा \n",
            "ल ि स ् ब न \n",
            "अ ज _ क े _ क ो ग ा र े \n",
            "अ ा ग व ं त ी \n",
            "र े ड न _ क े स \n",
            "क ु ं ज न ा \n",
            "क ् ल ि य ो _ क व ा र ् ड \n",
            "ह ल व ा न ी \n",
            "य ो ग े ं द ् र \n",
            "म ु े े _ स ी न े _ स े _ ल ग ा _ ल ो \n",
            "ब ो व ा ल \n",
            "अ _ क ो ् ट र न ू न \n",
            "अ ा ट क र \n",
            "न ् य ू ट न \n",
            "अ ो ् ड ् र य ू \n",
            "स ु र ी न ा \n",
            "ग ं ग ा ं े र \n",
            "अ ा ब र ा \n",
            "अ ा ब र ा \n",
            "\n",
            "[STATUS] Batch 140/656 complete! Batch Loss: 0.1514228880405426\n",
            "0.983871\n",
            "140\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 141 optimized output for Epoch 0:\n",
            "अ ज ि य न \n",
            "ल े े \n",
            "म े व न _ प ा ं र ि स \n",
            "अ ा क ं ा \n",
            "ज े न ी \n",
            "अ ो ि ज ी \n",
            "क ि र ा \n",
            "र ा म ू व ा ल ि य ा \n",
            "न े ी र ा \n",
            "न व _ ं ा र त \n",
            "अ ो ं द ा \n",
            "ब ल ं स \n",
            "द ि ल द ा र \n",
            "अ म ज द \n",
            "व ि व े क ा \n",
            "म ु स ् त ह स न \n",
            "ब ो ं ब ी क _ क ो र ् ट \n",
            "ब ु ं र ा \n",
            "अ ो र ् ट _ व स र ् ड न \n",
            "स े र ा _ ड स स _ प र ग ा ं स \n",
            "\n",
            "[STATUS] Batch 141/656 complete! Batch Loss: 0.13150084018707275\n",
            "0.983871\n",
            "141\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 142 optimized output for Epoch 0:\n",
            "न ा ज ी \n",
            "अ स द \n",
            "अ ो ो ब ल े \n",
            "ग ो र े \n",
            "न ो ग ु व ी _ म ् य ु ि य म \n",
            "ज ो क ् व े स _ क ल ल ि स \n",
            "य ू न ि व र ् स ि ट ी _ प ड _ स ा व ो _ क ् व ी न ् स ल ं ड \n",
            "स ा व न _ क ो _ क न े _ द ो \n",
            "अ ो क ा न \n",
            "म ह ं ि ं द ् र ा _ य ू न ा ज ट े ड _ व र ् ल ् ड _ क स ल े ज _ प ड _ स ं ड ि य ा \n",
            "अ ो र ् ट _ म ा ं ल ् स \n",
            "प ् र ा प ् त ि \n",
            "ग ल ल ि य म \n",
            "अ र ब ी \n",
            "अ र े ब ी य न \n",
            "ब र क ् ल ल ज \n",
            "प ् र ो ं ो ि न ल ल ं ड ि य ा _ म े ड ल \n",
            "अ ज ा द \n",
            "र ो ट ी _ क प ं ा _ ो र _ म क ा न \n",
            "अ ा ह ा \n",
            "\n",
            "[STATUS] Batch 142/656 complete! Batch Loss: 0.23037530481815338\n",
            "0.9725807\n",
            "142\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 143 optimized output for Epoch 0:\n",
            "व ो र ् स ा _ क स ् र े ड र ी क _ ो प ि न \n",
            "ल ा द े न _ ब ि ज ा न ी \n",
            "द ो _ द ि क ा र ी \n",
            "अ ो ु न ि क \n",
            "क ो ो _ प र ् ड र ् ट न \n",
            "अ ा म ो ं _ स ि प ा ह ी \n",
            "ब ि ज ल ी \n",
            "द ो ह र ी ा ट \n",
            "अ स ् स े ल _ प ् र ो प े क \n",
            "अ क ् ज र \n",
            "ज ग द ी द व ा न \n",
            "म े ह व द ी \n",
            "म े ह ं द ी \n",
            "अ ज ी त _ क ग र क र \n",
            "प ् र ि य त म ा \n",
            "प ो ट े म क ि न \n",
            "अ र ा ब ी \n",
            "अ ् र ी म ा \n",
            "र ा ज द ् र ी \n",
            "अ ल ा \n",
            "\n",
            "[STATUS] Batch 143/656 complete! Batch Loss: 0.15689024329185486\n",
            "0.9806452\n",
            "143\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 144 optimized output for Epoch 0:\n",
            "न ू र _ ज _ ड ल ा ह ी \n",
            "द _ ड ् र े ट ं ग _ स े ं ट र \n",
            "ज ल स ा \n",
            "ह ब ू स \n",
            "न ु ट ज व ो ट ि न \n",
            "ह ो ब ी _ ब े क र _ क व ा र ् ड \n",
            "ब न व ा ल ी \n",
            "अ द ् ट व ा क ी \n",
            "क े म ल \n",
            "ब ज र ं ग \n",
            "अ ो ् र ा ं ज व _ ह े न ी य ल \n",
            "म ा र ् स े ड ल े \n",
            "स म र ् द \n",
            "अ ट ि स \n",
            "क ु द म द \n",
            "न े म _ न ो न \n",
            "ह ं ग े र ि य न _ र ि व स ल ् ट \n",
            "स े ं ट _ स ् ट े न ि स ् ल स स _ ह ा द _ स ् क ू ल ड _ म ु म ् ब ड \n",
            "अ म ी म \n",
            "अ ज ा र ् य न ं द न ा \n",
            "\n",
            "[STATUS] Batch 144/656 complete! Batch Loss: 0.1929369866847992\n",
            "0.9782258\n",
            "144\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 145 optimized output for Epoch 0:\n",
            "क ल ी म ा ं ट न \n",
            "अ ि ं ग ा र ी \n",
            "अ ल ी \n",
            "अ द ् ट व ा क ी \n",
            "अ ू द \n",
            "म ा ज द द ा _ म ो ट र \n",
            "व र ् क स ् ट ् र ी म \n",
            "अ ो ि न ा द \n",
            "ग ड द व ा ल \n",
            "अ ि ल ् प ा \n",
            "अ म ् ब ो ड ा ल ा \n",
            "अ र ् ल ा \n",
            "व ि द ् व े ं द ् र \n",
            "व न ा न ी \n",
            "व े ल क र \n",
            "स े ं ट _ ज _ र ् ट ् स _ क ड न ल \n",
            "प न े स र \n",
            "ज स प ा ल \n",
            "म द ि ल ् ड ा \n",
            "र े \n",
            "\n",
            "[STATUS] Batch 145/656 complete! Batch Loss: 0.11995042115449905\n",
            "0.983871\n",
            "145\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 146 optimized output for Epoch 0:\n",
            "द _ द क न _ म ट ि क _ ट ा ट म ् स \n",
            "ल ि य ो न ा र ् ड \n",
            "ग ं ग ा _ क ी _ स ग ं ं \n",
            "अ ल ह ा म \n",
            "म ो ं ट े \n",
            "क ् व ी न ् स ल ं ड र \n",
            "प ् य ा स ी _ न ि ग ा ह े ं \n",
            "द र ा र \n",
            "क न ि क ा \n",
            "स ं य ु क ् त ा \n",
            "ल ो र े ट ् ट ा \n",
            "क ु स ु म \n",
            "अ ल _ प ो त ो स ी \n",
            "अ द र ् ट \n",
            "स ि व ि ल ा \n",
            "ब ा ब ू ग द ब \n",
            "न े द न ल _ प ा र ् क ् स _ ट ट _ ब ् र ा ज ट ी ल \n",
            "अ े ल ् स ी \n",
            "अ द न ि य ा \n",
            "व र द र ा ज ा _ प े र ू म ा ल \n",
            "\n",
            "[STATUS] Batch 146/656 complete! Batch Loss: 0.14691033959388733\n",
            "0.983871\n",
            "146\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 147 optimized output for Epoch 0:\n",
            "अ ि क म ं ग ल ू र \n",
            "अ ग े _ क ी _ स ो \n",
            "ल ो ं ग ो व ा ल \n",
            "अ ं प ा \n",
            "ड ा य े न \n",
            "ड े ल व ि ल े _ ब प ट ि स ् ट \n",
            "न द े र े _ क य ल ं ड \n",
            "ज ल ं ग ी \n",
            "क ो क ा र ् क _ स ू र ् य \n",
            "अ ो र ी \n",
            "र ि ट र ् ड _ स ् न े ल \n",
            "र ु प ी \n",
            "ज व ा न ी \n",
            "म ा र ् ल ि स \n",
            "ब ा ल स ा \n",
            "क े द े _ ब े ट ् स \n",
            "अ ं ज ी न ि य र \n",
            "अ द े ल \n",
            "व ि ड ल र \n",
            "ह म _ म े व ा ल े _ न ज व ा न \n",
            "\n",
            "[STATUS] Batch 147/656 complete! Batch Loss: 0.13319416344165802\n",
            "0.9854839\n",
            "147\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 148 optimized output for Epoch 0:\n",
            "ब े म ् ब े _ व ा र \n",
            "श ि र ी न \n",
            "व ा द ल \n",
            "ब ा ल ो ् र ा \n",
            "ल े ड ा \n",
            "प ् र ि स ी ल ा _ प ् र ी स ् ल े \n",
            "ज ि त े न ् द ् र \n",
            "क ै ल \n",
            "ट े र ि य न \n",
            "व े ड ल े क \n",
            "ज ू ल ि य ा \n",
            "अ ल ् ट ि य ा \n",
            "ब े ल ा _ क ल \n",
            "क ् र ि ट ् ट ि य ा न ि ट ी \n",
            "म े ल ा \n",
            "ब ं द ् र ि म ा \n",
            "स ब ा _ क र ी म \n",
            "क ा व ा ब ा ट ा _ य स ु न ा र ी _ प ् र ा ट ट \n",
            "श े ट प ु ट \n",
            "ब ल ी प े \n",
            "\n",
            "[STATUS] Batch 148/656 complete! Batch Loss: 0.09878706187009811\n",
            "0.9887097\n",
            "148\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 149 optimized output for Epoch 0:\n",
            "व ल ु प ी \n",
            "ट ा र ् ट ट न _ ट ट ् ड _ क ो ब र ा \n",
            "क ा व _ र ो प ि ं ग \n",
            "प ो ल स \n",
            "म ो ट ो क ् र े स \n",
            "अ र ् ट े ग _ प ् र ा ट ट \n",
            "प ् र ि स ट ि ट न _ व ट ल ी _ क ॉ र व े ट _ म ् य ु ट ि य म \n",
            "द ा द ो ल क र \n",
            "श ् क े क _ प ् र ा ट ट _ ट न _ व ि ट ् य ु ल _ क र ् ट ् ट स \n",
            "ब ू ट \n",
            "न े न ् ग क ् र े म \n",
            "ड े र े क _ स ् ट र ल ि ं ग \n",
            "म द ा _ म ा र ् ट ि न \n",
            "ब ि ल _ क े े \n",
            "स ै न _ प ा ब ् ल ो _ ब े \n",
            "फ ो र ् ट _ ल े _ ब े य ू ट \n",
            "म े ल े ट \n",
            "अ म ो \n",
            "न े ु न _ द ट ि न \n",
            "ब ् ल े क _ क ट ल ल ं ड \n",
            "\n",
            "[STATUS] Batch 149/656 complete! Batch Loss: 0.21456444263458252\n",
            "0.96854836\n",
            "149\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 150 optimized output for Epoch 0:\n",
            "ह ि ल ् ट न _ ग ् र ु प \n",
            "र े न ी \n",
            "ज न ् ड े स ा \n",
            "म ा र क ो न ी _ प ् र ा ट ट \n",
            "फ ा व ज ी \n",
            "ल ल न क े स ् ट र \n",
            "म ै र ी \n",
            "म ै ल ् क म _ ब ै ल र ि ट _ न े श न ल _ क ् व ा ल ि ट ी _ क व ा र ् ड \n",
            "ज ि त े ं द ् र \n",
            "म ि श े ल _ ड ॉ ग ल ् स \n",
            "र ो म न ज ो \n",
            "ग े र ी \n",
            "अ ल ् ट ा \n",
            "ह ं ब े ा \n",
            "प ् र ि क ् स _ ग ॉ न क ो र ् ट \n",
            "ल े ा \n",
            "श ा य द \n",
            "ज े ि ं ग _ य ु न ि व र ् स ल _ ट ट ल ि ट ट ो न \n",
            "स ु म ि त ् र ा न ं द न _ प ं े \n",
            "स ो ल ो म न _ द ् व ी प \n",
            "\n",
            "[STATUS] Batch 150/656 complete! Batch Loss: 0.1491241455078125\n",
            "0.983871\n",
            "150\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 151 optimized output for Epoch 0:\n",
            "स म ् र ा ट _ क ं द ् र ग ु प ् ट \n",
            "अ म र ा श ् र ी \n",
            "क त ् र ी \n",
            "म ि म ी \n",
            "अ प न ा _ क े न \n",
            "फ ि ल ् म ो र \n",
            "क ी न न \n",
            "क े ल \n",
            "श न ं ज य \n",
            "क ो र ् न े ल ि य ा \n",
            "क म ी र े ट ् स _ ट ॉ व र _ व न \n",
            "ह ि न ् द ी \n",
            "व श \n",
            "द र ब ा न \n",
            "ब ा ल ि य ा \n",
            "म स ् त ा न ा _ म ा क \n",
            "म ा र ् ट ि न _ स ू ज ी \n",
            "ज ह ा न ा र ा \n",
            "श ि व प ् र ि य ा \n",
            "क ट ा व क र \n",
            "\n",
            "[STATUS] Batch 151/656 complete! Batch Loss: 0.10616515576839447\n",
            "0.99112904\n",
            "151\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 152 optimized output for Epoch 0:\n",
            "ह र े र \n",
            "क न ं द ी \n",
            "स ह ा र न प ु र \n",
            "ह म ् न ा ह \n",
            "ज े ा _ ज े ा \n",
            "अ क े ल े _ क म _ प क े ल े _ क ु म \n",
            "र े ड ी \n",
            "ब ि स ् त र \n",
            "ग ु ड ग ग ा व \n",
            "ग ु ड ग ग ा ं व \n",
            "ग ं ग ा ग ं ज \n",
            "ब ि क ् र म प ु र \n",
            "क ु स ु म ल ा \n",
            "क ै ल ि य ा \n",
            "क ग म \n",
            "प ॉ ल _ प ी ह न \n",
            "ज ं ग ल _ म े ं _ म ं ग ल \n",
            "ज ं ग ल _ क ी _ ब े ट ी \n",
            "फ ो र ् ट _ क ै र ो ल ी न \n",
            "क म ् ल ा _ ज ं क ् ट न \n",
            "\n",
            "[STATUS] Batch 152/656 complete! Batch Loss: 0.12266990542411804\n",
            "0.98629034\n",
            "152\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 153 optimized output for Epoch 0:\n",
            "क ा न ड े \n",
            "य ू न ि व र ् स ि ट ी _ प क _ ल ै ं क े स ् ट र \n",
            "म ज ब ू र \n",
            "र ू ग _ व े स ् ट ह ी म र \n",
            "ल क ि क ् न ो स ् ट े ट ट ि स _ प प न ं ट य र _ म ् य ु ट ि य म \n",
            "म ा र ् ट ि न _ क े ं ट \n",
            "र े ड _ क ं ल ै ं ड \n",
            "क ा ट क र \n",
            "ज ं म प ु र \n",
            "म े ग े ं \n",
            "ग ु ज र ा त _ प ल ् क ल ी \n",
            "क क ् त _ र ा ज \n",
            "ज न ् ज ि य ो ट े क _ क ़ ा र ् म ा स ु ट ि क ल ् स \n",
            "र े ड _ र ो ट \n",
            "ज ज ु त ा \n",
            "व ा क न ी स \n",
            "क ् र ि स ् ट ी _ क ै न ् ट ़ र \n",
            "क ो ल ा _ क ा ल ा \n",
            "व व े ल \n",
            "क ा ल े ल क र \n",
            "\n",
            "[STATUS] Batch 153/656 complete! Batch Loss: 0.18163058161735535\n",
            "0.9782258\n",
            "153\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 154 optimized output for Epoch 0:\n",
            "द े व _ क ु म ा र \n",
            "व े ब ् ज ़ े न \n",
            "र ं ग ी ल ा _ म ु स ा ि र \n",
            "श े र ी \n",
            "ल ै न ् स _ ग ि ब ् स \n",
            "ट ि म _ क क र ी \n",
            "ड ि ड ् र ि क ा \n",
            "ल ा स ् क र _ प व ा र ् ड \n",
            "ड ् र े क ् स ि स _ ह े ल ् य \n",
            "स ल ा म _ म े म स ा \n",
            "र े ब र _ ब ॉ श \n",
            "क ै स र _ प व ा र ् ड \n",
            "ह ु क \n",
            "व ा ह ब ा न \n",
            "ज ं द ् र ज ा \n",
            "फ ल न ा \n",
            "ड े ल ् ट ा _ क य र _ ल ा इ न ् स \n",
            "स ं ु ा ल ी \n",
            "फ ै र ा ग ट \n",
            "फ ि य ो न \n",
            "\n",
            "[STATUS] Batch 154/656 complete! Batch Loss: 0.10522874444723129\n",
            "0.9919355\n",
            "154\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 155 optimized output for Epoch 0:\n",
            "व ि श ् व \n",
            "ड ा ग ल ा \n",
            "ह ो ी \n",
            "अ द ् ट व ा क ी \n",
            "अ म े र ि क न _ व ा र _ प क _ क ं ड ि प े ं ड े ं स \n",
            "फ ि ल ो _ व ै ल े स \n",
            "ल े ल ि य ा \n",
            "स म ् य क \n",
            "द ु र े ं ं ा _ ज ं क ् ट न \n",
            "न ै र ी \n",
            "ज स ो द ा \n",
            "ट ॉ म _ स ी ल क \n",
            "क ु ं ग ं द ् र ा \n",
            "म स ् त _ क क ी र \n",
            "ब ै र ी _ क ै ड ल ी \n",
            "र ो स म न ् ड \n",
            "म ि स _ म न ो र म ा \n",
            "प ै न े स ि य ा _ ब ा य ो ट े क \n",
            "अ ं ि य ं द ् र \n",
            "ह ु र \n",
            "\n",
            "[STATUS] Batch 155/656 complete! Batch Loss: 0.13515928387641907\n",
            "0.9854839\n",
            "155\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 156 optimized output for Epoch 0:\n",
            "ग ै ल ि य ा \n",
            "क श ी _ न े ह र ा \n",
            "न ू र \n",
            "व े ल ् स _ क ़ ा र ् ग ो \n",
            "क र े ज ि य स \n",
            "स ् ट ु ग र ् ट _ ल ॉ \n",
            "ब े क ु ब ा न \n",
            "क े श ि ी \n",
            "स ि स ि ल ि य ा \n",
            "न ा ग न _ ह ॉ र ि ट ् ट \n",
            "ज ै ल ै ं ड \n",
            "ग ि स े ल ी \n",
            "अ ह म द \n",
            "फ ै र ु ज ़ \n",
            "द _ ट ा य न े _ ट र े ट ् ट स \n",
            "फ ो र ् ट _ ह ै म ि ल ् ट न \n",
            "क ा फ े क र \n",
            "व े र ् ि य ा _ क ो क ल ो र _ म ् य ु ि य म \n",
            "अ क ब र \n",
            "व ि र े श \n",
            "\n",
            "[STATUS] Batch 156/656 complete! Batch Loss: 0.12508505582809448\n",
            "0.98790324\n",
            "156\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 157 optimized output for Epoch 0:\n",
            "ब ा र ब र ा _ म ा र ् क ् स _ ह ब र ् ड \n",
            "म ज ् द \n",
            "स ि म ा _ प ् य ु म ा क ो क ा \n",
            "ज ब ् र ा \n",
            "श फ क त \n",
            "श फ क ा त \n",
            "ल ो व र _ न ि र ा र _ र ि य र व ा य र \n",
            "व ि य ो ग ी \n",
            "श ै ल स ु त ा \n",
            "स ल ् ल \n",
            "ज ो र े _ क ा _ क ा य \n",
            "क र न ् न ु म \n",
            "ड ब ् ल क ि न _ र ा इ ट र ् स _ म ् य ु ट ि य म \n",
            "ज म प ् ल े स े ब ल \n",
            "ज प ् र ि ल \n",
            "ज क _ न य ा _ र ि श ् त ा \n",
            "क ा म ज ु र ी \n",
            "व ् ह ा इ ट क ॉ म ् ब \n",
            "द र ् द ् स ं द ि ल \n",
            "ड ग म ग प ु र \n",
            "\n",
            "[STATUS] Batch 157/656 complete! Batch Loss: 0.1296371966600418\n",
            "0.98790324\n",
            "157\n",
            "[NOTIFICATION] Translation file saved to: drive/My Drive/data_PA3/TRAINING_TRANSLATION_OUTPUT_EPOCH_0_STATE-SIZE_512_NUM-LAYERS_1_LEARNING-RATE0.001_EMBEDDING-SIZE_256.txt\n",
            "[INFO]: Batch 158 optimized output for Epoch 0:\n",
            "न ं द क ि श ो र "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b9e1d4cf6782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[INFO]: Batch {} optimized output for Epoch {}:'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_total_cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;31m# newlines imply flush in subprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mevent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevent_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    389\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[1;32m    390\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "9Ikyz0rp0Aid",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_one_hot = vectorize_data(y_data, Y_MAX_LENGTH, y_word_to_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-9G4RGt3x_qj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cvOSNB4syAAb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_model_path  = \"drive/My Drive/data_PA3/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JBk-gXZ60BZm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "\n",
        "    g = tf.get_default_graph()\n",
        "\n",
        "    new_saver = tf.train.import_meta_graph(save_model_path + '-0' + '.meta')\n",
        "\n",
        "    new_saver.restore(sess, tf.train.latest_checkpoint(save_model_path))\n",
        "    \n",
        "    _current_state = np.zeros((encoder_layers, 2,  batch_size, state_size))\n",
        "    \n",
        "    \n",
        "    with tf.name_scope('decoder', reuse=tf.AUTO_REUSE) as scope:\n",
        "      _prediction_series = sess.run(\n",
        "              [ prediction],\n",
        "              feed_dict={\n",
        "                      encoder_x: x_data_valid,\n",
        "                      decoder_x: y_data_valid,\n",
        "                      y: y_one_hot,\n",
        "                      init_state: _current_state\n",
        "                  })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O55mONY-Ccg2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}